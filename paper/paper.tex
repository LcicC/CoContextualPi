\documentclass[sigplan,screen,review]{acmart}

\usepackage[inline]{enumitem}

\renewcommand*{\sectionautorefname}{\S\!\!\,}
\renewcommand*{\subsectionautorefname}{\S\!\!\,}

% Typing rules
\usepackage{mathpartir}
\mprset {sep=0.5em} % Horizontal space between premises

\newcommand{\picalc}{$\pi$-calculus}
\newcommand{\Picalc}{$\pi$-Calculus}
\newcommand{\rulename}[1]{{\tiny \textsc{(#1)}}}
\newcommand{\constr}[1]{\textcolor{olive}{\mathtt{#1}}}
\newcommand{\func}[1]{\textcolor{gray}{\mathtt{#1}}}
\newcommand{\type}[1]{\textcolor{blue}{\mathtt{#1}}}

% Syntax types
\newcommand{\Fin}[1]{\type{Fin}~#1}
\newcommand{\fzero}{\constr{zero}}
\newcommand{\fsuc}{\constr{suc}}
\newcommand{\sExpr}[1]{\type{Expr}~#1}
\newcommand{\sProc}[1]{\type{Proc}~#1}
\newcommand{\tvar}[2]{#1 ~\type{\ni_t}~ #2}
\newcommand{\tkind}[2]{#1 ~\type{\vdash_t}~ #2}
\newcommand{\ttype}[1]{\type{Type}~#1}
\newcommand{\tusage}[1]{\type{Usage}~#1}
\newcommand{\tCtx}[2]{\type{Ctx}_{#1}~#2}
\newcommand{\tSplit}[3]{#1~\type{=}~#2~\type{\uplus}~#3}
\newcommand{\tEq}[2]{#1~\type{\equiv}~#2}
\newcommand{\tun}[1]{\type{un}~#1}
\newcommand{\tVar}[3]{#1 ~ \type{\ni} ~ #2 ~ \type{:} ~ #3}
\newcommand{\tExpr}[3]{#1 ~ \type{\vdash} ~ #2 ~ \type{:} ~ #3}
\newcommand{\tProc}[2]{#1 ~ \type{\vdash} ~ #2}
\newcommand{\tConstr}[1]{\type{Constr} ~ #1}
\newcommand{\tConstrs}[1]{\type{[Constr} ~ #1 ~ \type{]}}

% Syntax constructors
\newcommand{\sunit}{\constr{unit}}
\newcommand{\svar}{\constr{var}}
\newcommand{\sfst}{\constr{fst}}
\newcommand{\ssnd}{\constr{snd}}
\newcommand{\sinl}{\constr{inl}}
\newcommand{\sinr}{\constr{inr}}
\newcommand{\spair}{\constr{pair}}
\newcommand{\send}{\constr{end}}
\newcommand{\snew}{\constr{new}}
\newcommand{\scomp}{\constr{comp}}
\newcommand{\srecv}{\constr{recv}}
\newcommand{\ssend}{\constr{send}}
\newcommand{\scase}{\constr{case}}
\newcommand{\srec}{\constr{rec}}

% Kind constructors
\newcommand{\ktype}{\constr{ty}}
\newcommand{\kusage}{\constr{us}}

% Typing judgment constructors
\newcommand{\tmvar}{\constr{mvar}}
\newcommand{\tchan}{\constr{chan}}
\newcommand{\tunit}{\constr{unit}}
\newcommand{\tsum}{\constr{sum}}
\newcommand{\tprod}{\constr{prod}}
\newcommand{\tzero}{\constr{0\cdot}}
\newcommand{\tone}{\constr{1\cdot}}
\newcommand{\tomega}{\constr{\omega\cdot}}

\newcommand{\subst}[2]{#1 ~ \func{\triangleleft} ~ #2}
\newcommand{\tSubst}[2]{\type{Subst}~#1~#2}
\newcommand{\interpr}[1]{\func{[\![} #1 \func{]\!]}}

% Constraint constructors
\newcommand{\eqconstr}[2]{\constr{[} ~ #1 ~ \constr{\stackrel{c}{=}} ~ #2 ~ \constr{]}}
\newcommand{\sumconstr}[3]{\constr{[} ~ #1 ~ \constr{\stackrel{c}{=}} ~ #2 ~ \constr{+} ~ #3 ~ \constr{]}}

\title
[Co-Contextual Typing Inference for the Linear \Picalc{} in Agda]
{Co-Contextual Typing Inference \\ for the Linear \Picalc{} in Agda}
\subtitle{(Extended Abstract)}

\author{Uma Zalakain}
\affiliation{University of Glasgow}
\email{u.zalakain.1@research.gla.ac.uk}

\author{Ornela Dardha}
\affiliation{University of Glasgow}
\email{ornela.dardha@glasgow.ac.uk}

\begin{document}

\begin{abstract}
  While a \picalc{} with linear types ensures the privacy and safety of concurrent communication, allowing unrestricted non-linear communication is key to model real-world services.
  To implement a decision procedure that type checks a \picalc{} process with linear and shared types without relying on user-provided type annotations we must infer the types of the channels created within the process.
  If we limit ourselves to the shared \picalc{}, we can traverse the process bottom-up and eagerly solve typing constraints into substitutions and apply them to the typing context.
  However, in a setting with both linear and shared types, typing constraints do not always come with a most general solution, and thus cannot always be eagerly solved.

  We follow Padovani \cite{Padovani15} and provide a \emph{co-contextual typing inference} \cite{ErdwegBKKM15} algorithm that traverses processes bottom-up and, in addition to the typing context, collects a set of typing constraints.
  We then solve those constraints that have a most general solution (by using well-known unification algorithms \cite{McBride03}) while deferring the rest until more information becomes available.
  We state clear soundness and completeness theorems separating both these phases, and a progress theorem that ensures that only those constraints without a most general solution are deferred.
  The totality of this work is being mechanised in Agda.
\end{abstract}


\maketitle

\section{Introduction}\label{introduction}

The \picalc{} \cite{MilnerPW92a,Milner99} models concurrent processing, boiling it down to the transmission of data over communication channels --- where channels too are sent as payload.
The linear \picalc{} \cite{KobayashiPT96} introduces a type system that ensures that every channel is used \emph{exactly} once.
This restriction ensures communication privacy, communication safety, and the absence of race conditions.
We generalise to a \picalc{} with linear and shared types, where the input and output multiplicities of a channel are either $0$ (cannot be used to transmit), $1$ (must be used exactly once), or $\omega$ (unrestricted use).

To type check a \picalc{} process with shared and linear types we must assign a type to every communication channel created within the process.
To do so we can either ask the user for type annotations \cite{ZalakainD21}, or we can infer types by looking at how channels are used.
We follow this latter approach: we traverse processes bottom-up while keeping a typing context with \emph{metavariables} (\emph{holes}) and collecting typing constraints on metavariables, in line with co-contextual typing \cite{ErdwegBKKM15}.
Keeping a strictly bottom-up information flow has the additional advantage of making typing inference easily parallelisable.
Constraints with a most general solution are solved into substitutions and applied to the typing context, constraints without one must be kept around for later: applying them as substitutions risks over-constraining the problem down the line.
Armed with a typing inference algorithm that for a process $P$ infers the most general typing context $\Gamma$ and some typing constraints, type checking that $\Delta \vdash P$ for some $\Delta$ amounts to emitting the extra constraint $\Gamma = \Delta$, assuming the metavariables in $\Gamma$ and $\Delta$ are disjoint.

To the best of our knowledge, this problem has only been treated in Padovani's work on type reconstruction for composite types \cite{Padovani15}.
However, his work does not appear to be mechanised, and metatheoretical properties like soundness and completeness are only informally addressed.
With this work, we aim to:
\begin{itemize}
  \item State and prove clear soundness and completeness theorems for both constraint collection (\autoref{constraint-collection}) and constraint resolution (\autoref{constraint-resolution}).
  \item Mechanise in Agda the totality of this work.
\end{itemize}

We start defining an untyped but well scoped \picalc{} using type-level de Bruijn indices \cite{deBruijn72} and embed a small expression language that handles composite sum and product types.
On top, we define a standard type system with linear and shared types using context-splits \autoref{type-system}.
We then provide an overview of how typing inference works, define constraint collection (\autoref{constraint-collection}) and constraint resolution (\autoref{constraint-resolution}), and state that both phases are sound and complete with regards to the type system defined in \autoref{type-system}.

We have proven that constraint collection is sound and (adapting McBride's work \cite{McBride03} to deal with intrinsically kinded terms) that the resolution of equality constraints is sound too.
The remaining proofs are still in progress.
(A note on notation: variables are black, \textcolor{blue}{types are blue}, \textcolor{olive}{constructors are green}, \textcolor{gray}{functions are gray}, and we are sorry this is not a poem.)


\section{Type System}
\label{type-system}

We define a standard syntax and type system for the linear \picalc{}.
The only non-standard feature is that types allow for \emph{metavariables} within them.

\paragraph{Syntax}

We define a standard syntax for the \picalc{} using type-level de Bruijn indices.
Variable references $i_n$ are of type $\Fin{n}$, expressions $e_n$ and $f_n$ are of type $\sExpr{n}$, processes $p_n$ and $q_n$ are of type $\sProc{n}$.
\[
\begin{aligned}[c]
  e_n ~ f_n  :=
  &~ \sunit \\
  |&~ \svar~i_n \\
  |&~ \spair~e_n~f_n \\
  |&~ \sfst~e_n ~|~  \ssnd~e_n \\
  |&~ \sinl~e_n ~|~  \sinr~e_n
\end{aligned}
\begin{aligned}[c]
  p_n ~ q_n  :=
  &~ \send ~|~  \srec~p_n ~|~ \snew~p_{1+n} \\
  |&~ \srecv~e_n~p_{1+n} \\
  |&~ \ssend~e_n~f_n~p_n \\
  |&~ \scomp~p_n~q_n \\
  |&~ \scase~e_n~p_{1+n}~q_{1+n} \\
\end{aligned}
\]

\paragraph{Types}
\label{types}


Both types and usage annotations contain metavariables.
We use a common set of metavariables for both --- this makes their handling uniform.
A context of kinds \(\gamma\) keeps track of whether a metavariable is of type kind $\ktype$ or usage annotation kind $\kusage$.
We refer to a metavariable of kind \(k\) in a kinding context \(\gamma\) as $\tvar{\gamma}{k}$.
We can now define usage annotations and types in one go (we define $\tzero$, $\tone$ $\tomega$ at once for brevity):
\begin{mathpar}
  \inferrule {m : \tvar{\gamma}{k}} {\tmvar~m : \tkind{\gamma}{k}}

  \inferrule {
    i : \tkind{\gamma}{\kusage} \\
    o : \tkind{\gamma}{\kusage} \\
    t : \tkind{\gamma}{\ktype}}
  {\tchan~i~o~t : \tkind{\gamma}{\ktype}}

  \inferrule { }
  {\tunit : \tkind{\gamma}{\ktype}}

  \inferrule {s : \tkind{\gamma}{\ktype} \\ t : \tkind{\gamma}{\ktype} }
  {\tprod~s~t : \tkind{\gamma}{\ktype}}

  \inferrule {s : \tkind{\gamma}{\ktype} \\ t : \tkind{\gamma}{\ktype} }
  {\tsum~s~t : \tkind{\gamma}{\ktype}}

  \inferrule { } {\tzero ~|~ \tone ~|~ \tomega : \tkind{\gamma}{\kusage}}
\end{mathpar}
We henceforth use $\ttype{\gamma}$ for $\tkind{\gamma}{\ktype}$ and $\tusage{\gamma}$ for $\tkind{\gamma}{\kusage}$.

\paragraph{Context Splits}
\label{types}
A context $\Gamma$ of type $\tCtx{n}{\gamma}$ is a list of $\ttype{\gamma}$ of size $n$.
We define context splits $\tSplit{\Gamma}{\Delta}{\Theta}$ pointwise on types.
Splits on types are defined recursively on usage annotations --- note that only the usage annotations at the top of a channel are split, not those within its payload.
Splits on usage annotations are defined as follows:
\begin{mathpar}
  \inferrule { } {\tSplit{x}{x}{\tzero}}

  \inferrule { } {\tSplit{x}{\tzero}{x}}

  \inferrule { } {\tSplit{\tomega}{x}{y}}
\end{mathpar}
Following \cite{Padovani15}, a context $\Gamma$ is unrestricted (shared, non-linear) $\tun{\Gamma}$ if it can be split into itself: $\tSplit{\Gamma}{\Gamma}{\Gamma}$ (respectively $\tun{x}$ and $\tun{t}$ for usage annotations $x$ and types $t$).

\paragraph{Typing Judgments}
\label{typing-judgments}
We can finally define our typing judgment for variables, expressions and processes (some cases are omitted for brevity).

\begin{mathpar}
%  \inferrule { \Gamma : \tCtx{n}{\gamma} \\ i : \Fin{n} \\ t : \ttype{\gamma} }
%             { \tVar{\Gamma}{i}{t} }

  \inferrule { \Gamma : \tCtx{n}{\gamma} \\ \tun{\Gamma} \\ t : \ttype{\gamma} }
             { \tVar{\Gamma,t}{\fzero}{t} }
             % \rulename{zero}

  \inferrule { \tVar{\Gamma}{i}{t} \\ s : \ttype{\gamma} \\ \tun{s} }
             { \tVar{\Gamma,s}{\fsuc~i}{t} }
             % \rulename{suc}

%  \inferrule { \Gamma : \tCtx{n}{\gamma} \\ e : \sExpr{n} \\ t : \ttype{\gamma}}
%             { \tExpr{\Gamma}{e}{t} }

  \inferrule { \tVar{\Gamma}{i}{t} } { \tExpr{\Gamma}{\svar~i}{t} }
             % \rulename{var}

  \inferrule { \tun{\Gamma} } { \tExpr{\Gamma}{\sunit}{\tunit} }
             % \rulename{unit}

  \inferrule { \tExpr{\Gamma}{e}{\tprod~t~s} \\ \tun{s}} {\tExpr{\Gamma}{\sfst~e}{t}}
             % \rulename{fst}

  \inferrule { \tExpr{\Gamma}{e}{t} } { \tExpr{\Gamma}{\sinl~e}{\tsum~t~s}}
             % \rulename{inl}

  \inferrule { \tSplit{\Gamma}{\Delta}{\Theta} \\ \tExpr{\Delta}{e}{s} \\ \tExpr{\Theta}{f}{t} }
             { \tExpr{\Gamma}{\spair~e~f}{\tprod~s~t}}
             %\rulename{pair}

%  \inferrule { \Gamma : \tCtx{n}{\gamma} \\ p : \sProc{n}}
%             { \tProc{\Gamma}{p} }

  \inferrule { \tun{\Gamma} } { \tProc{\Gamma}{\send} }
             %\rulename{end}

  \inferrule { \tProc{\Gamma}{p} \\ \tun{\Gamma} }
             { \tProc{\Gamma}{\srec~p} }
             %\rulename{rec}

  \inferrule { t : \ttype{\gamma} \\ \tProc{\Gamma , t}{p} } { \tProc{\Gamma}{\snew~p} }
             %\rulename{new}

  \inferrule { \tSplit{\Gamma}{\Delta}{\Theta} \\ \tExpr{\Delta}{e}{\tchan~\tone~\tzero~t} \\ \tProc{\Theta,t}{p} }
             { \tProc{\Gamma}{\srecv~e~p} }
             %\rulename{recv}

  \inferrule { \tSplit{\Gamma}{\Delta}{\Theta} \\ \tExpr{\Delta}{e}{\tsum~s~t} \\ \tProc{\Theta,s}{p} \\ \tProc{\Theta,t}{q} }
             { \tProc{\Gamma}{\scase~e~p~q} }
             %\rulename{case}
\end{mathpar}

     
\section{Inference}\label{inference}

Co-contextual typing inference traverses processes bottom-up keeping a typing context and collecting constraints.
This makes inference subproblems independent and thus easily parallelisable.
In the shared \picalc{}, inference constraints always have a most general unifier, in the shared \emph{and} linear \picalc{} however they do not.
Consider the open process $\ssend~a~\sunit~(\ssend~x~a~\send)$ where $x$ and $a$ are free: we partly use $a$ to send, then send $a$ away over $x$ and terminate.
When the process terminates, all multiplicities must be unrestricted, but we cannot decide whether to instantiate with $\tzero$ or $\tomega$.
Similarly, we ignore \emph{how much} of $a$ we are sending away over $x$: that depends on what the receiving process expects.
Nonetheless, we do have to keep track of the fact that $a$ has been used once to send.

In \autoref{constraint-collection} we introduce typing constraints, and define kind-preserving substitution, constraint satisfaction, and a typing inference algorithm.
We show that satisfying the constraints generated by typing inference is enough to make a process typable (soundness), and postulate that for any typable process typing inference will find the most general set of constraints that makes the process typable (completeness).

In \autoref{constraint-resolution} we solve equality constraints by unification and context split constraints by decomposition.
Constraints with a most general solution can be solved into substitutions.
(Constraints without a most general solution can be solved by instantiation once the process is closed.)
Solving a set of constraints thus results in a set of substitutions and a set of simplified constraints that had those substitutions applied.
We postulate that satisfying the simplified constraints amounts to satisfying the original constraints after substitution (soundness), and that for every substitution that solves the original constraints we can find a most general substitution that will solve the simplified constraints (completeness).
Additionally, we postulate that the simplified set of constraints only contains constraints without a most general solution (progress).

\subsection{Constraint Collection}
\label{constraint-collection}

\paragraph{Constraints}

Constraints of type $\tConstr{\gamma}$ are defined on arguments of type $\tkind{\gamma}{k}$ for some $k$ --- that is, on both usage annotations and types.
They take two forms: the binary $\eqconstr{S}{T}$, where $S$ and $T$ must be unified, and the ternary $\sumconstr{S}{T}{R}$, where $T$ and $R$ must add up to $S$.
Constraints of the former form can \emph{always} be eagerly solved, while constraints of the latter can \emph{sometimes} not.
We use $\tConstrs{\gamma}$ to refer to lists of constraints of type $\tConstr{\gamma}$.

\paragraph{Substitution}

A kind-preserving substitution $\tSubst{\gamma}{\delta}$ maps usage annotations and type metavariables in $\gamma$ to usage annotations and types in $\delta$, that is, $\forall k \to \tvar{\gamma}{k} \to \tkind{\delta}{k}$.
The function $\subst{\sigma}{t}$ of type $\tSubst{\gamma}{\delta} \to (\forall k \to \tkind{\gamma}{k} \to \tkind{\delta}{k})$ performs the substitution by replacing all the metavariables in $t$ with their corresponding terms in $\sigma$.
Substitutions on constraints are defined pointwise on their arguments.


\paragraph{Constraint Satisfaction}

We use a $\interpr{\_}$ function to interpret constraints $\eqconstr{S}{T}$ and $\sumconstr{S}{T}{R}$ into their reified counterparts $\tEq{S}{T}$ and $\tSplit{S}{T}{R}$, respectively.

\paragraph{Inference}

Typing inference takes a process with $n$ free variables and returns a metavariable context $\gamma$, a typing context with $n$ free variables containing metavariables in $\gamma$, and a list of constraints on metavariables $\gamma$.
We define a similar function for typing inference on expressions, this time also returning a type $\tau$ of type $\ttype{\gamma}$:
\begin{flalign*}
& \func{inferProc} : \sProc{n} \to ~ \exists \gamma. ~ \tCtx{n}{\gamma} \times \tConstrs{\gamma} && \\
& \func{inferExpr} : \sExpr{n} \to ~ \exists \gamma. ~ \tCtx{n}{\gamma} \times \tConstrs{\gamma} \times \ttype{\gamma} &&
\end{flalign*}
These functions are total: if a process or expression is untypable its constraints will be unsolvable.

Let us provide a couple of examples illustrating how this function is defined:
For the expression $\sfst~e$ we
\begin{enumerate*}[label=\textcolor{gray}{\arabic*)}]
  \item recursively infer $e$ resulting in $\gamma,\Gamma,Cs,\tau$;
  \item add two fresh type metavariables $?t$ and $?s$ to $\gamma$;
  \item add constraints $\eqconstr{\tau}{\tprod~?t~?s}$ and $\sumconstr{?s}{?s}{?s}$ to $Cs$; and
  \item return $?t$ as the type of $\sfst~e$.
\end{enumerate*}

For the expression $\scase~e~p~q$ we
  \begin{enumerate*}[label=\textcolor{gray}{\arabic*)}]
  \item infer $p$ resulting in $\theta_p, (\Theta_p, s) , Cs_p$;
  \item infer $q$ resulting in $\theta_q, (\Theta_q, t) , Cs_q$;
  \item infer $e$ resulting in $\delta_e, \Delta_e, Cs_e, \tau$;
  \item create a new metavariable context $\gamma$ and a new typing context $\Gamma$ where every type is a fresh metavariable in $\gamma$;
  \item take the union of the metavariables in $\gamma$, $\theta_p$, $\theta_q$ and $\delta_e$;
  \item take the union of the constraints in $Cs_p$, $Cs_q$ and $Cs_e$, and create new constraints $\eqconstr{\Theta_p}{\Theta_q}$, $\sumconstr{\Gamma}{\Delta_e}{\Theta_p}$, and $\eqconstr{\tau}{\tsum~s~t}$; and
  \item return $\Gamma$ as the inferred context.
\end{enumerate*}

\paragraph{Inference Soundness}

Given $\tEq{\func{infer}~p}{\gamma , \Gamma , cs}$, every substitution \(\sigma\) that makes the constraints $cs$ hold makes $\tProc{(\subst{\sigma}{\Gamma})}{p}$ hold.

\paragraph{Inference Completeness}

Given $\tEq{\func{infer}~p}{\gamma , \Gamma , cs}$, for every context \(\Delta\) that makes $p$ typable, there exists a substitution \(\sigma\) that solves the constraints $cs$ such that $\Delta$ is a specialisation of $(\subst{\sigma}{\Gamma})$ --- a specialisation $\Delta ~ \func{\subseteq} ~ (\subst{\sigma}{\Gamma})$ is defined as $\exists \sigma_f . ~ \tEq{\Delta}{(\subst{\sigma_f}{(\subst{\sigma}{\Gamma})})}$.

\subsection{Constraint Resolution}
\label{constraint-resolution}

Solving a set of constraints results in a set of substitutions and an unsolved set of simplified constraints where those substitutions have already been applied.
The constraints that have been left unsolved do not have a most general solution.
Constraints of the form $\eqconstr{x}{y}$ are solved by unification using a kinded version of McBride's unification by structural recursion \cite{McBride03}, and have either no solution, or a most general solution that results in a substitution.
Constraints of the form $\sumconstr{x}{y}{z}$ are solved recursively until a base case is reached, at which point they either have a most general solution or they do not.
$$
\begin{aligned}
\func{solve} &: \tConstrs{\gamma} \to \tSubst{\gamma}{\delta} \times \tConstrs{\delta}
\end{aligned}
$$

\paragraph{Resolution Soundness}

Given $\tEq{\func{solve}~cs_1}{(\sigma, cs_2)}$, every substitution $\sigma_f$ that satisfies the simplified constraints ($\interpr{\subst{\sigma_f}{cs_2}}$) satisfies the original constraints after substitutions are applied ($\interpr{\subst{\sigma_f}{(\subst{\sigma}{cs_1})}}$).

\paragraph{Resolution Completeness}

Given $\tEq{\func{solve}~cs_1}{(\sigma, cs_2)}$, any substitution \(\sigma_f\) that makes the original constraints \(cs_1\) hold ($\interpr{\subst{\sigma_f}{cs_1}}$) can be decomposed into $\sigma$ followed by a certain \(\sigma_g\) ($\sigma_f ~ \type{\doteq} ~ \sigma_g \cdot \sigma$) that makes the returned constraints \(cs_2\) hold ($\interpr{\subst{\sigma_g}{cs_2}}$).

\paragraph{Resolution Progress}

Given $\func{solve}~cs_1 \equiv (\sigma, cs_2)$, to keep us from returning the original constraints as output (which is both sound and complete), we postulate that none of the constraints $c \in cs_2$ has a most general solution, where a most general solution for a constraint $c$ is defined as $\exists \sigma. ~ \interpr{\subst{\sigma}{c}} \times (\forall \sigma_f . ~ \interpr{\subst{\sigma_f}{c}} \times (\exists \sigma_g. ~ \sigma_f ~ \type{\doteq} ~ \sigma_g \cdot \sigma))$.

\bibliographystyle{abbrvnat}
\bibliography{paper}
\end{document}