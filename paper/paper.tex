\documentclass[sigplan,screen,review]{acmart}

\usepackage[inline]{enumitem}
\usepackage{todonotes}

\theoremstyle{definition}\newtheorem{mytheorem}{Theorem}[section]
\renewcommand*{\sectionautorefname}{\S\!\!\,}
\renewcommand*{\subsectionautorefname}{\S\!\!\,}

% Typing rules
\usepackage{mathpartir}
\mprset {sep=0.6em} % Horizontal space between premises

\newcommand{\picalc}{$\pi$-calculus}
\newcommand{\Picalc}{$\pi$-Calculus}
\newcommand{\rulename}[1]{{\tiny \textsc{(#1)}}}
\newcommand{\var}[1]{\textcolor{black}{\mathnormal{#1}}}
\newcommand{\constr}[1]{\textcolor{olive}{\mathtt{#1}}}
\newcommand{\func}[1]{\textcolor{gray}{\mathtt{#1}}}
\newcommand{\type}[1]{\textcolor{blue}{\mathtt{#1}}}

% Syntax types
\newcommand{\Fin}[1]{\type{Fin}~#1}
\newcommand{\fzero}{\constr{zero}}
\newcommand{\fsuc}{\constr{suc}}
\newcommand{\sExpr}[1]{\type{Expr}~#1}
\newcommand{\sProc}[1]{\type{Proc}~#1}
\newcommand{\tvar}[2]{#1 ~\type{\ni_t}~ #2}
\newcommand{\tkind}[2]{#1 ~\type{\vdash_t}~ #2}
\newcommand{\ttype}[1]{\type{Type}~#1}
\newcommand{\tusage}[1]{\type{Usage}~#1}
\newcommand{\tCtx}[2]{\type{Ctx}_{#1}~#2}
\newcommand{\tSplit}[3]{#1~\type{=}~#2~\type{\uplus}~#3}
\newcommand{\tEq}[2]{#1~\type{\equiv}~#2}
\newcommand{\tun}[1]{\type{un}~#1}
\newcommand{\tVar}[3]{#1 ~ \type{\ni} ~ #2 ~ \type{:} ~ #3}
\newcommand{\tExpr}[3]{#1 ~ \type{\vdash} ~ #2 ~ \type{:} ~ #3}
\newcommand{\tProc}[2]{#1 ~ \type{\vdash} ~ #2}
\newcommand{\tConstr}[1]{\type{Constr} ~ #1}
\newcommand{\tConstrs}[1]{\type{[Constr} ~ #1 ~ \type{]}}

% Syntax constructors
\newcommand{\sunit}{\constr{unit}}
\newcommand{\svar}{\constr{var}}
\newcommand{\sfst}{\constr{fst}}
\newcommand{\ssnd}{\constr{snd}}
\newcommand{\sinl}{\constr{inl}}
\newcommand{\sinr}{\constr{inr}}
\newcommand{\spair}{\constr{pair}}
\newcommand{\send}{\constr{end}}
\newcommand{\snew}{\constr{new}}
\newcommand{\scomp}{\constr{comp}}
\newcommand{\srecv}{\constr{recv}}
\newcommand{\ssend}{\constr{send}}
\newcommand{\scase}{\constr{case}}
\newcommand{\srec}{\constr{rec}}

% Kind constructors
\newcommand{\ktype}{\constr{ty}}
\newcommand{\kusage}{\constr{us}}

% Typing judgment constructors
\newcommand{\tmvar}{\constr{mvar}}
\newcommand{\tchan}[3]{\constr{chan}_{\constr{[}#1\constr{,}#2\constr{]}} ~ #3}
\newcommand{\tunit}{\constr{unit}}
\newcommand{\tsum}{\constr{sum}}
\newcommand{\tprod}{\constr{prod}}
\newcommand{\tzero}{\constr{0\cdot}}
\newcommand{\tone}{\constr{1\cdot}}
\newcommand{\tomega}{\constr{\omega\cdot}}

\newcommand{\subst}[2]{#1 ~ \func{\triangleleft} ~ #2}
\newcommand{\tSubst}[2]{\type{Subst}~#1~#2}
\newcommand{\interpr}[1]{\func{\llbracket} #1 \func{\rrbracket}}

% Constraint constructors
\newcommand{\eqconstr}[2]{\constr{[} ~ #1 ~ \constr{\stackrel{c}{=}} ~ #2 ~ \constr{]}}
\newcommand{\sumconstr}[3]{\constr{[} ~ #1 ~ \constr{\stackrel{c}{=}} ~ #2 ~ \constr{+} ~ #3 ~ \constr{]}}
\newcommand{\varconstr}[3]{\constr{[} ~ #1 ~ \constr{\stackrel{c}{\ni}_{\var{#2}}} ~ #3 ~ \constr{]}}

\title
[Co-Contextual Typing Inference for the Linear \Picalc{} in Agda]
{Co-Contextual Typing Inference \\ for the Linear \Picalc{} in Agda}
\subtitle{(Extended Abstract)}

\author{Uma Zalakain}
\affiliation{University of Glasgow}
\email{u.zalakain.1@research.gla.ac.uk}

\author{Ornela Dardha}
\affiliation{University of Glasgow}
\email{ornela.dardha@glasgow.ac.uk}

\begin{document}

\begin{abstract}
  A \picalc{} with linear types ensures the privacy and safety of concurrent communication.
  Allowing shared (unlimited) communication however is key to model real-world services.
  To implement a decision procedure that type checks a \picalc{} process with both linear and shared types one can either rely on user-provided type annotations, or infer the types of the channels created within the process.
  We choose to reduce the burden on the user by following the latter approach.
  If we limit ourselves to the shared \picalc{}, we can traverse a process bottom-up and eagerly solve typing constraints into substitutions and apply them to the typing context.
  However, in a setting with both linear and shared types, typing constraints do not always come with a most general solution, and thus cannot always be eagerly solved.

  We provide a \emph{co-contextual typing inference} \cite{ErdwegBKKM15} algorithm that traverses processes bottom-up and, in addition to the typing context, collects a set of typing constraints.
  We then solve those constraints that have a most general solution (by using well-known unification algorithms \cite{McBride03}) while deferring the rest until more information becomes available.
  We state clear soundness and completeness theorems separating both these phases, and a progress theorem that ensures that only those constraints without a most general solution are deferred.
  This work is being mechanised in Agda.
\end{abstract}


\maketitle

\section{Introduction}\label{introduction}

The \picalc{} \cite{MilnerPW92a,Milner99} models concurrent processing, boiling it down to the transmission of data over communication channels --- where channels too are sent as payload.
Type systems for the \picalc{} that support linearity \cite{KobayashiPT96} ensure that linear channels are used \emph{exactly once}, which guarantees communication safety and the absence of race conditions.
We follow this line of work with a \picalc{} with linear and shared types, where the input and output capabilities of a channel are either usage $0$ (cannot be used to transmit), usage $1$ (must be used exactly once), or usage $\omega$ (unlimited use).
\footnote{
  Why support a usage $0$ instead of removing the variable from context altogether? it allows the syntax to be independent from the type system, and moreover for a \emph{polarised} treatment of channels, where the same channel variable is used for both input and output.
  }

To type check a \picalc{} process with shared and linear types we must assign a type to every communication channel created within the process.
To do so we can either ask the user for type annotations \cite{ZalakainD21}, or we can infer types by looking at how channels are used.
To reduce the burden on the user, we follow the latter approach: we traverse processes bottom-up while keeping a typing context with \emph{metavariables} (\emph{holes}) and collecting typing constraints on metavariables, in line with co-contextual typing \cite{ErdwegBKKM15}.
Keeping a strictly bottom-up information flow has the additional advantage of making typing inference parallelisable.
Constraints with a most general solution are solved into substitutions and applied to the typing context, constraints without must be kept around for later: applying them as substitutions risks over-constraining the problem down the line.
Armed with a typing inference algorithm that for a process $P$ infers the most general typing context $\Gamma$ and some typing constraints, type checking that $\Delta \vdash P$ for some $\Delta$ amounts to emitting the extra constraint $\Gamma = \Delta$, assuming the metavariables in $\Gamma$ and $\Delta$ are disjoint.

To the best of our knowledge, this problem has not yet been mechanised, and has only been treated in Padovani's work on type reconstruction for composite types \cite{Padovani15}.
With this work, we aim to:
\begin{itemize}
  \item State and prove clear soundness and completeness theorems for both constraint collection and constraint resolution (\autoref{inference}).
  \item Mechanise in Agda the totality of this work.
\end{itemize}

We start defining an untyped but well scoped \picalc{} using type-level de Bruijn indices \cite{deBruijn72} and embed a small expression language that handles composite sum and product types.
On top, we define a standard type system with linear and shared types using context-splits (\autoref{type-system}).
We then provide an overview of how typing inference works, define constraint collection and constraint resolution (\autoref{inference}), and state that both phases are sound and complete with regards to the type system defined in \autoref{type-system}.
(Notation: variables are black, \textcolor{blue}{types are blue}, \textcolor{olive}{constructors are green}, and \textcolor{gray}{functions are gray}.)


\section{Type System}
\label{type-system}

We define a standard syntax and type system for the linear \picalc{}.
The only non-standard feature is that types allow for \emph{metavariables} within them.

\paragraph{Syntax}

We define a standard syntax for the \picalc{} using type-level de Bruijn indices.
Variable references $i_{1+n}$ are of type $\Fin{(1 + n)}$ with constructors $\fzero$ and $\fsuc~i_n$, expressions $e_n$ and $f_n$ are of type $\sExpr{n}$, processes $p_n$ and $q_n$ are of type $\sProc{n}$.
\[
\begin{aligned}[c]
  e_n ~ f_n  :=
  &~ \sunit \\
  |&~ \svar~i_n \\
  |&~ \spair~e_n~f_n \\
  |&~ \sfst~e_n ~|~  \ssnd~e_n \\
  |&~ \sinl~e_n ~|~  \sinr~e_n
\end{aligned}
\begin{aligned}[c]
  p_n ~ q_n  :=
  &~ \send ~|~  \srec~p_n ~|~ \snew~p_{1+n} \\
  |&~ \srecv~e_n~p_{1+n} \\
  |&~ \ssend~e_n~f_n~p_n \\
  |&~ \scomp~p_n~q_n \\
  |&~ \scase~e_n~p_{1+n}~q_{1+n} \\
\end{aligned}
\]

\paragraph{Types}
\label{types}


Both types and usage annotations contain metavariables.
To make their handling uniform we use a common set of metavariables for both.
A context of kinds \(\gamma\) keeps track of whether a metavariable is of type kind $\ktype$ or usage annotation kind $\kusage$.
Variable references $m$ are of type $\tvar{\gamma}{k}$: the set of variables of kind \(k\) in a kinding context \(\gamma\).
Usage annotations $i$ and $o$ are of type $\tkind{\gamma}{\kusage}$, and types $s$ and $t$ of type $\tkind{\gamma}{\ktype}$.
We henceforth abbreviate $\tkind{\gamma}{\ktype}$ as $\ttype{\gamma}$ and $\tkind{\gamma}{\kusage}$ as $\tusage{\gamma}$.
\[
\begin{aligned}[c]
  i ~ o :=& ~ \tmvar_{\kusage} ~ m ~|~ \tzero ~|~ \tone ~|~ \tomega \\
  s ~ t :=& ~ \tmvar_{\ktype} ~ m ~|~ \tunit ~|~ \tchan{i}{o}{t} ~|~ \tprod ~ s ~ t ~|~ \tsum ~ s ~ t
\end{aligned}
\]

\paragraph{Context Splits}
\label{types}
A context $\Gamma$ of type $\tCtx{n}{\gamma}$ is a list of $\ttype{\gamma}$ of size $n$.
We define context splits $\tSplit{\Gamma}{\Delta}{\Theta}$ pointwise on types.
Splits on types are defined pointwise on usage annotations (but are not applied to a channel's payload) and splits on usage annotations are defined as follows:
\begin{mathpar}
  \inferrule { } {\tSplit{x}{x}{\tzero}}

  \inferrule { } {\tSplit{x}{\tzero}{x}}

  \inferrule { } {\tSplit{\tomega}{x}{y}}

  \inferrule {\tSplit{i_x}{i_y}{i_z} \\ \tSplit{o_x}{o_y}{o_z}} {\tSplit{\tchan{i_x}{o_x}{t}}{\tchan{i_y}{o_y}{t}}{\tchan{i_z}{o_z}{t}}}
\end{mathpar}
Note that e.g., both $\tSplit{\tzero}{\tzero}{\tzero}$ and $\tSplit{\tomega}{\tzero}{\tzero}$ are possible: we use context splits to allow the type system to lose granularity.
Following \cite{Padovani15}, a context $\Gamma$ is unrestricted (non-linear) $\tun{\Gamma}$ if it can be split into itself: $\tSplit{\Gamma}{\Gamma}{\Gamma}$ (respectively $\tun{x}$ and $\tun{t}$ for usage annotations $x$ and types $t$).

\paragraph{Typing Judgments}
\label{typing-judgments}
We can now define our typing judgment for variables ($\tVar{\Gamma}{i}{t}$, where variable $i$ under context $\Gamma$ is of type $t$), expressions ($\tExpr{\Gamma}{e}{t}$, where expression $e$ under context $\Gamma$ is well typed with type $t$) and processes ($\tProc{\Gamma}{p}$, where process $p$ is well typed under context $\Gamma$).
Note that, although fully linear tensor products ($\tprod ~ s ~ t$) cannot directly be eliminated through their projections ($\sfst$ rule), context splits enable their usage annotations to be distributed beforehand.
Similarly, while it may appear that $\srecv$ and $\ssend$ only work on channels with usages ($\tone$, $\tzero$) and vice versa, the context splits in these rules allow usages to lose granularity (and thus accept e.g., ($\tomega$, $\tomega$)).

\begin{mathpar}
  \inferrule { \Gamma : \tCtx{n}{\gamma} \\ \tun{\Gamma} \\ t : \ttype{\gamma} }
             { \tVar{\Gamma,t}{\fzero}{t} }

  \inferrule { \tVar{\Gamma}{i}{t} \\ s : \ttype{\gamma} \\ \tun{s} }
             { \tVar{\Gamma,s}{\fsuc~i}{t} }

  \inferrule { \tExpr{\Gamma}{e}{\tprod~t~s} \\ \tun{s}} {\tExpr{\Gamma}{\sfst~e}{t}}

  \inferrule { \tSplit{\Gamma}{\Delta}{\Theta} \\ \tExpr{\Delta}{e}{s} \\ \tExpr{\Theta}{f}{t} }
             { \tExpr{\Gamma}{\spair~e~f}{\tprod~s~t}}

  \inferrule { \tun{\Gamma} } { \tProc{\Gamma}{\send} }

  \inferrule { t : \ttype{\gamma} \\ \tProc{\Gamma , t}{p} } { \tProc{\Gamma}{\snew~p} }

  \inferrule { \tSplit{\Gamma}{\Delta}{\Theta} \\ \tExpr{\Delta}{e}{\tchan{\tone}{\tzero}{t}} \\ \tProc{\Theta,t}{p} }
             { \tProc{\Gamma}{\srecv~e~p} }

  \mprset{flushleft}
  \inferrule {
    \tSplit{\Gamma}{\Delta}{\Theta} \\\\
    \tSplit{\Theta}{\Psi}{\Xi} \\
    \tExpr{\Delta}{f}{\tchan{\tzero}{\tone}{t}} \\
    \tExpr{\Psi}{e}{t} \\
    \tProc{\Xi}{p}
  }
  { \tProc{\Gamma}{\ssend~f~e~p} }
\end{mathpar}

     
\section{Inference}\label{inference}

\paragraph{Constraints}

Constraints of type $\tConstr{\gamma}$ are defined on arguments of type $\tkind{\gamma}{k}$ for some $k$ --- that is, on both usage annotations and types.
They take two forms: the binary $\eqconstr{S}{T}$, where $S$ and $T$ must be unified, and the ternary $\sumconstr{S}{T}{R}$, where $S$ is split into $T$ and $R$.
Constraints are pointwise lifted to typing contexts, and we abbreviate with $\varconstr{\Gamma}{i}{t}$ a constraint that states that $i$ must be of type $t$ in $\Gamma$, and all other variables in $\Gamma$ must be unrestricted.
We use $\tConstrs{\gamma}$ to refer to lists of constraints of type $\tConstr{\gamma}$.

\paragraph{Substitution}

A kind-preserving substitution $\tSubst{\gamma}{\delta}$ maps usage annotations and type metavariables in $\gamma$ to usage annotations and types in $\delta$, that is, $\forall \{k\} \to \tvar{\gamma}{k} \to \tkind{\delta}{k}$ for an implicit $k$.
The function $\subst{\sigma}{t}$ of type $\tSubst{\gamma}{\delta} \to (\forall \{k\} \to \tkind{\gamma}{k} \to \tkind{\delta}{k})$ performs the substitution by replacing all the metavariables in $t$ with their corresponding terms in $\sigma$.
Substitutions on constraints are defined pointwise on their arguments.


\paragraph{Constraint Satisfaction}

We use a $\interpr{\_}$ function to interpret constraints $\eqconstr{S}{T}$ and $\sumconstr{S}{T}{R}$ into claims of their satisfiability $\tEq{S}{T}$ and $\tSplit{S}{T}{R}$, respectively.

\paragraph{Inference}

Typing inference takes a process with $n$ free variables and returns a metavariable context $\gamma$, a typing context with $n$ free variables containing metavariables in $\gamma$, and a list of constraints on metavariables $\gamma$.
We define a similar function for typing inference on expressions, this time also returning a type in $\ttype{\gamma}$.
These functions are total: if a process or expression is untypable its constraints are unsolvable.
\begin{flalign*}
& \func{inferProc} : \sProc{n} \to ~ \exists \gamma. ~ \tCtx{n}{\gamma} \times \tConstrs{\gamma} && \\
& \func{inferExpr} : \sExpr{n} \to ~ \exists \gamma. ~ \tCtx{n}{\gamma} \times \tConstrs{\gamma} \times \ttype{\gamma} &&
\end{flalign*}

Unlike in the shared \picalc{}, where constraints have always a most general unifier, in the shared \emph{and} linear \picalc{} metavariables can be under-constrained.
Consider the open process $\ssend~a~\sunit~(\ssend~x~a~\send)$ where $x$ and $a$ are free: we partly use $a$ to send, then send whatever is left of $a$ away over $x$ and terminate.
Let us step through a working example of how inference runs:
\begin{enumerate}
  \item on $\send$, inference creates a fresh typing context $\Gamma_0$ with metavariables for $x$ and $a$, and constraints demanding that these should be unrestricted.
  \item on $\ssend ~ x ~ a$, inference creates fresh typing contexts $\Gamma_4$, $\Gamma_3$, $\Gamma_2$ and $\Gamma_1$, a fresh metavariable $?t$, and constraints $\sumconstr{\Gamma_4}{\Gamma_3}{\Gamma_2}$, $\varconstr{\Gamma_3}{x}{\tchan{\tzero}{\tone}{?t}}$, $\sumconstr{\Gamma_2}{\Gamma_1}{\Gamma_0}$, and $\varconstr{\Gamma_1}{a}{?t}$, following the typing rules.
  \item on $\ssend ~ a ~ \sunit$, inference creates fresh typing contexts $\Gamma_6$ and $\Gamma_5$, and constraints $\sumconstr{\Gamma_6}{\Gamma_5}{\Gamma_4}$, and $\varconstr{\Gamma_5}{a}{\tchan{\tzero}{\tone}{\tunit}}$.
\end{enumerate}

Here \emph{usage polymorphism} on $?t$ makes inference under-constrained and prevents us from finding a most general solution:
the constraints on $a$'s type demand that it must be split into $\tchan{\tzero}{\tone}{\tunit}$, into $?t$, and into some unrestricted leftovers, and while $?t$ can eagerly be substituted by a channel type $\tchan{?i}{?o}{\tunit}$ for some $?i$ and $?o$, it is polymorphic in its usage annotations $?i$ and $?o$.
In other words, we must keep track of the partial usage of $a$ while allowing $x$ to be polymorphic in the type of $a$.
As a result, these partial usage constraints must be kept around (potentially until the process is closed and they can be solved by instantiation) and meta-theoretical properties must therefore be abstracted over constraint satisfaction.

\begin{mytheorem}[Inference Soundness]\label{inference-soundness}
Given $\func{infer}~p$ returns $(\gamma , \Gamma , cs)$, every substitution \(\sigma\) satisfying $\interpr{\subst{\sigma}{cs}}$ makes $\tProc{(\subst{\sigma}{\Gamma})}{p}$ hold.
\end{mytheorem}

\begin{mytheorem}[Inference Completeness]\label{inference-completeness}
Given $\func{infer}~p$ returns $(\gamma , \Gamma , cs)$, for every context \(\Delta\) such that $\tProc{\Delta}{p}$, there exists a substitution \(\sigma\) satisfying $\interpr{\subst{\sigma}{cs}}$ such that $\Delta$ is a specialisation of $(\subst{\sigma}{\Gamma})$ --- a specialisation $\Delta ~ \func{\subseteq} ~ (\subst{\sigma}{\Gamma})$ is defined as $\exists \sigma_f . ~ \tEq{\Delta}{(\subst{\sigma_f}{(\subst{\sigma}{\Gamma})})}$.
\end{mytheorem}

\subsection{Constraint Resolution}
\label{constraint-resolution}

Solving a set of constraints results in a set of substitutions and an unsolved set of simplified constraints where those substitutions have already been applied.
The constraints that have been left unsolved do not have a most general solution.
Constraints of the form $\eqconstr{x}{y}$ are solved by unification using a kinded version of McBride's unification by structural recursion \cite{McBride03}, and have either no solution, or a most general solution that results in a substitution.
Constraints of the form $\sumconstr{x}{y}{z}$ are solved recursively until a base case is reached, at which point they either have a most general solution or they do not.
$$
\begin{aligned}
\func{solve} &: \tConstrs{\gamma} \to \tSubst{\gamma}{\delta} \times \tConstrs{\delta}
\end{aligned}
$$

\begin{mytheorem}[Resolution Soundness]\label{resolution-soundness}
Given $\func{solve}~cs_1$ returns $(\sigma, cs_2)$, every substitution $\sigma_f$ that satisfies the simplified constraints ($\interpr{\subst{\sigma_f}{cs_2}}$) satisfies the original constraints after substitutions are applied ($\interpr{\subst{\sigma_f}{(\subst{\sigma}{cs_1})}}$).
\end{mytheorem}

\begin{mytheorem}[Resolution Completeness]\label{resolution-completeness}
Given $\func{solve}~cs_1$ returns $(\sigma, cs_2)$, any substitution \(\sigma_f\) that makes the original constraints \(cs_1\) hold ($\interpr{\subst{\sigma_f}{cs_1}}$) can be decomposed into $\sigma$ followed by a certain \(\sigma_g\) ($\sigma_f ~ \type{\doteq} ~ \sigma_g \cdot \sigma$) that makes the returned constraints \(cs_2\) hold ($\interpr{\subst{\sigma_g}{cs_2}}$).
\end{mytheorem}

\begin{mytheorem}[Resolution Progress]\label{resolution-progress}
Given $\func{solve}~cs_1$ returns $(\sigma, cs_2)$, to keep us from returning the original constraints as output (which is both sound and complete), we postulate that none of the constraints $c \in cs_2$ has a most general solution, where a most general solution for a constraint $c$ is defined as $\exists \sigma. ~ \interpr{\subst{\sigma}{c}} \times (\forall \sigma_f . ~ \interpr{\subst{\sigma_f}{c}} \times (\exists \sigma_g. ~ \sigma_f ~ \type{\doteq} ~ \sigma_g \cdot \sigma))$.
\end{mytheorem}

\section{Discussion}

We have outlined a procedure for decidable type checking and inference of a \picalc{} with linear and shared types.
Constraint collection and constraint resolution are kept separate, and their metatheory allows for deferred constraints.
We have proved in Agda the soundness of constraint collection \autoref{inference-soundness} and of equality constraint resolution \autoref{resolution-soundness}, the remaining proofs are still in progress.

\bibliographystyle{abbrvnat}
\bibliography{paper}
\end{document}
