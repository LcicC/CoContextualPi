\documentclass[sigplan,screen,review]{acmart}

\usepackage{todonotes}

% Typing rules
\usepackage{mathpartir}
\mprset {sep=1em} % Horizontal space between premises

\newcommand{\picalc}{$\pi$-calculus}
\newcommand{\Picalc}{$\pi$-Calculus}
\newcommand{\rulename}[1]{{\tiny \textsc{(#1)}}}
\newcommand{\constr}[1]{\textcolor{olive}{\mathtt{#1}}}
\newcommand{\type}[1]{\textcolor{blue}{\mathtt{#1}}}

% Syntax types
\newcommand{\Fin}[1]{\type{Fin}~#1}
\newcommand{\fzero}{\constr{zero}}
\newcommand{\fsuc}{\constr{suc}}
\newcommand{\sExpr}[1]{\type{Expr}~#1}
\newcommand{\sProc}[1]{\type{Proc}~#1}
\newcommand{\tvar}[2]{#1 ~\type{\ni_t}~ #2}
\newcommand{\tkind}[2]{#1 ~\type{\vdash_t}~ #2}
\newcommand{\ttype}[1]{\type{Type}~#1}
\newcommand{\tusage}[1]{\type{Usage}~#1}
\newcommand{\tCtx}[2]{\type{Ctx}_{#1}~#2}
\newcommand{\tSplit}[3]{#1~\type{=}~#2~\type{\uplus}~#3}
\newcommand{\tun}[1]{\type{un}~#1}
\newcommand{\tVar}[3]{#1 ~ \type{\ni} ~ #2 ~ \type{:} ~ #3}
\newcommand{\tExpr}[3]{#1 ~ \type{\vdash} ~ #2 ~ \type{:} ~ #3}
\newcommand{\tProc}[2]{#1 ~ \type{\vdash} ~ #2}

% Syntax constructors
\newcommand{\sunit}{\constr{unit}}
\newcommand{\svar}{\constr{var}}
\newcommand{\sfst}{\constr{fst}}
\newcommand{\ssnd}{\constr{snd}}
\newcommand{\sinl}{\constr{inl}}
\newcommand{\sinr}{\constr{inr}}
\newcommand{\spair}{\constr{pair}}
\newcommand{\send}{\constr{end}}
\newcommand{\snew}{\constr{new}}
\newcommand{\scomp}{\constr{comp}}
\newcommand{\srecv}{\constr{recv}}
\newcommand{\ssend}{\constr{send}}
\newcommand{\scase}{\constr{case}}

% Kind constructors
\newcommand{\ktype}{\constr{ty}}
\newcommand{\kusage}{\constr{us}}

% Type constructors
\newcommand{\tmvar}{\constr{mvar}}
\newcommand{\tchan}{\constr{chan}}
\newcommand{\tunit}{\constr{unit}}
\newcommand{\tsum}{\constr{sum}}
\newcommand{\tprod}{\constr{prod}}
\newcommand{\tzero}{\constr{0\cdot}}
\newcommand{\tone}{\constr{1\cdot}}
\newcommand{\tomega}{\constr{\omega\cdot}}

\title{Extended Abstract}
\subtitle{Co-Contextual Type Inference for the Linear \Picalc{} in Agda}

\author{Uma Zalakain}
\affiliation{University of Glasgow}
\email{u.zalakain.1@research.gla.ac.uk}

\author{Ornela Dardha}
\affiliation{University of Glasgow}
\email{ornela.dardha@glasgow.ac.uk}

\begin{document}

\begin{abstract}
  The linear \picalc{} is a well-known substructural type system for the \picalc{}:
  it is a common target for the encoding of session-typed languages \cite{DardhaGS17},
  and it in direct correspondence with classical linear logic \todo{cite}.

  Type inference for the linear \picalc{} comes with its own challenges:
  for one, processes themselves are untyped, and thus typing constraints only apply to the typing contexts;
  moreover, typing constraints on usage annotations \emph{cannot always be eagerly solved in open processes}.

  We approach the first challenge using \emph{co-contextual type inference} \cite{ErdwegBKKM15}, where processes are traversed bottom-up and constraints are collected (and when possible eagerly solved) and merged on context splits.
  We approach the latter challenge by allowing the resolution of some of the constraints to be deferred.
  We state soundness and completeness theorems that take this deferral of constraint resolution into account.
  We state a progress (?) theorem that shows that only those constraints that need to be deferred are deferred.
  \todo{be more precise}
  We are working on mechanising our work in Agda.
\end{abstract}


\maketitle

\section{Introduction}\label{introduction}

We define an untyped but well scoped \picalc{} using type-level de Bruijn \cite{deBruijn72} indices \autoref{syntax}.
We define a small expression language within the process syntax to handle composite sum and product types.
On top of the well-scoped syntax we provide the standard linear type-system using context-splits \autoref{type-system}.
The type system is indexed by a typing context that admits unsolved metavariables.
These unsolved metavariables are however well kinded: either types or usage annotations.

\todo{insert example showing why we need deferral}

We split typing inference into constraint collection and constraint solving \autoref{inference}.
We start by defining constraints on types and usage annotations \autoref{constraints}
We collect constraints bottom-up, creating extra \emph{merging} constraints on context splits.
This allows type-inference to be easily parallelisable.
We postulate soundness and completeness theorems that allow for constraint solving to be deferred \autoref{inference-theorems}.


\section{Syntax}\label{syntax}

Expressions $e_n$ and $f_n$ are of type $\sExpr{n}$, processes $p_n$ and $q_n$ are of type $\sProc{n}$, variable references $i_n$ are of type $\Fin{n}$.
\[
\begin{aligned}[c]
  e_n ~ f_n  :=
  &~ \sunit \\
  |&~ \svar~i_n \\
  |&~ \spair~e_n~f_n \\
  |&~ \sfst~e_n ~|~  \ssnd~e_n \\
  |&~ \sinl~e_n ~|~  \sinr~e_n
\end{aligned}
\begin{aligned}[c]
  p_n ~ q_n  :=
  &~ \send ~|~  \snew~p_{1+n} \\
  |&~ \srecv~e_n~p_{1+n} \\
  |&~ \ssend~e_n~f_n~p_n \\
  |&~ \scomp~p_n~q_n \\
  |&~ \scase~e_n~p_{1+n}~q_{1+n}
\end{aligned}
\]
\todo{add recursion}
\todo{add type assertions}

\section{Type System}\label{type-system}

Both types and usage annotations allow for \emph{holes} or \emph{metavariables}.
We use the same set of metavariables for both types and usage annotations -- this makes their handling more uniform.
We use a context of kinds \(\gamma\) to keep track of whether a metavariable is of type kind $\ktype$ or usage annotation kind $\kusage$: a choice of kind \(k\) in a kinding context \(\gamma\) is denoted as $\tvar{\gamma}{k}$.

We define well kinded types and usage annotations simultaneously so that we are able to provide a uniform unification and context merge algorithm later on (note that we define $\tsum$ and $\tprod$ and $\tzero$, $\tone$ and $\tomega$ in one go to save space):
\begin{mathpar}
  \inferrule {m : \tvar{\gamma}{k}} {\tmvar~m : \tkind{\gamma}{k}}

  \inferrule {
    i : \tkind{\gamma}{\kusage} \\
    o : \tkind{\gamma}{\kusage} \\
    t : \tkind{\gamma}{\ktype}}
  {\tchan~i~o~t : \tkind{\gamma}{\ktype}}

  \inferrule { }
  {\tunit : \tkind{\gamma}{\ktype}}

  \inferrule {s : \tkind{\gamma}{\ktype} \\ t : \tkind{\gamma}{\ktype} }
  {\tsum~s~t ~|~ \tprod~s~t : \tkind{\gamma}{\ktype}}

  \inferrule { } {\tzero ~|~ \tone ~|~ \tomega : \tkind{\gamma}{\kusage}}
\end{mathpar}
We will henceforth use $\ttype{\gamma}$ to stand for $\tkind{\gamma}{\ktype}$ and $\tusage{\gamma}$ to stand for $\tkind{\gamma}{\kusage}$.

A context $\Gamma$ of type $\tCtx{n}{\gamma}$ is a list of $\ttype{\gamma}$ of size $n$.
We define context splits $\tSplit{\Gamma}{\Delta}{\Theta}$ pointwise on types.
Splits on types are defined pointwise recursively on usage annotations -- note however that only the usage annotations on the top level of a channel (that is, not within its payload) are split.
Splits on usage annotations are defined as follows -- note that they are not necessarily unique:
\begin{mathpar}
  \inferrule { } {\tSplit{x}{x}{\tzero}}

  \inferrule { } {\tSplit{x}{\tzero}{x}}

  \inferrule { } {\tSplit{\tomega}{x}{y}}
\end{mathpar}

A usage annotation $x$, type $t$ or context $\Gamma$ is unrestricted (shared, non-linear) $\tun{\Gamma}$ if it can be split into itself: $\tSplit{\Gamma}{\Gamma}{\Gamma}$ (respectively $x$ and $t$) \cite{Padovani15}.

We can finally define our typing judgment for variables, expressions and processes.

\begin{mathpar}
%  \inferrule { \Gamma : \tCtx{n}{\gamma} \\ i : \Fin{n} \\ t : \ttype{\gamma} }
%             { \tVar{\Gamma}{i}{t} }

  \inferrule { \Gamma : \tCtx{n}{\gamma} \\ \tun{\Gamma} \\ t : \ttype{\gamma} }
             { \tVar{\Gamma,t}{\fzero}{t} }
             \rulename{zero}

  \inferrule { \tVar{\Gamma}{i}{t} \\ s : \ttype{\gamma} \\ \tun{s} }
             { \tVar{\Gamma,s}{\fsuc~i}{t} }
             \rulename{suc}

%  \inferrule { \Gamma : \tCtx{n}{\gamma} \\ e : \sExpr{n} \\ t : \ttype{\gamma}}
%             { \tExpr{\Gamma}{e}{t} }

  \inferrule { \tVar{\Gamma}{i}{t} } { \tExpr{\Gamma}{\svar~i}{t} } \rulename{var}

  \inferrule { \tun{\Gamma} } { \tExpr{\Gamma}{\sunit}{\tunit} } \rulename{unit}

  \inferrule { \tExpr{\Gamma}{e}{\tprod~t~s} \\ \tun{s}} { \tExpr{\Gamma}{\sfst~e}{t}} \rulename{fst}

  \inferrule { \tExpr{\Gamma}{e}{t} } { \tExpr{\Gamma}{\sinl~e}{\tsum~t~s}} \rulename{inl}

  \inferrule { \tSplit{\Gamma}{\Delta}{\Theta} \\ \tExpr{\Delta}{e}{s} \\ \tExpr{\Theta}{f}{t} }
             { \tExpr{\Gamma}{\spair~e~f}{\tprod~s~t}}
             \rulename{pair}

%  \inferrule { \Gamma : \tCtx{n}{\gamma} \\ p : \sProc{n}}
%             { \tProc{\Gamma}{p} }

  \inferrule { \tun{\Gamma} } { \tProc{\Gamma}{\send} } \rulename{end}

  \inferrule { t : \ttype{\gamma} \\ \tProc{\Gamma , t}{p} } { \tProc{\Gamma}{\snew~p} }
             \rulename{new}

  \inferrule { \tSplit{\Gamma}{\Delta}{\Theta} \\ \tExpr{\Delta}{e}{\tchan~\tone~\tzero~t} \\ \tProc{\Theta,t}{p} }
             { \tProc{\Gamma}{\srecv~e~p} }
             \rulename{recv}

  \inferrule { \tSplit{\Gamma}{\Delta}{\Theta} \\ \tExpr{\Delta}{e}{\tsum~s~t} \\ \tProc{\Theta,s}{p} \\ \tProc{\Theta,t}{q} }
             { \tProc{\Gamma}{\scase~e~p~q} }
             \rulename{case}
\end{mathpar}

     
\section{Inference}\label{inference}

Co-contextual type inference: traverses the syntax bottom up, collecting
constraints on the typing context.

Constraints can be of the following form:

\begin{itemize}
\item
  \(S = T\): types \(S\) and \(T\) must be unifiable.
\item
  \(S = T + R\): adding up the usage annotations in \(T\) and \(R\) must
  result in \(S\).
\end{itemize}

Constraints of the form \(S = T\) can always be eagerly unified. However
constraints of the form \(S = T + R\) might contain variables:
\(\texttt{mvar}~x = \texttt{mvar}~y + \texttt{mvar}~z\). In an open
process, these variables cannot safely be instantiated to \(0\). As
such, no substitution is possible, yet we need to remember the
constraint. (It might also be that some constraints have more than one
possible solution.) At the same time, we need to show that the
constraints that we postulate are enough to solve the problem.

\paragraph{Constraint Satisfaction}

The \([\![\_]\!]\) function interprets constraints into their type
counterparts \(S \equiv T\) and \(S = T + R\). Substituting into a
constraint substitutes pointwise.

\paragraph{Inference}

\[
\texttt{infer} : \forall (p : \texttt{Proc}~n). ~ \exists \gamma. ~ \texttt{Ctx}~n~\gamma \times \texttt{List}~(\texttt{Constr}~\gamma)
\]

\paragraph{Inference soundness.}

Every substitution \(\sigma\) that makes the constraints hold will make
the process typable under the substituted context. \[
\begin{aligned}
\texttt{infer-sound} &: \forall (p : \texttt{Proc}~n). ~ \texttt{infer}~P \equiv \gamma , \Gamma , cs \\
&\to \forall (\sigma : \texttt{Subst}~\gamma~\delta). ~ [\![ \sigma \triangleleft cs ]\!] \\
&\to (\sigma \triangleleft \Gamma) \vdash P
\end{aligned}
\]

\paragraph{Inference completeness.}

For every context \(\Delta\) that makes the process typable there exists
a most general substitution \(\sigma\) that will solve the constraints
and which substitutes in \(\Gamma\) to something more general than
\(\Delta\). \[
\begin{aligned}
\texttt{infer-complete} &: \forall (p : \texttt{Proc}~n). ~ \texttt{infer}~P \equiv \gamma , \Gamma , cs \\
&\to \forall (\Delta : \texttt{Ctx}~n~\gamma). ~ \Delta \vdash P \\
&\to \exists \delta. ~ \exists (\sigma : \texttt{Subst}~\gamma~\delta). \\
&\to [\![ \sigma \triangleleft cs ]\!] \times \Delta \subseteq (\sigma \triangleleft \Gamma)
\end{aligned}
\] where \[
\Delta \subseteq \Gamma \triangleq \exists \delta. ~ \exists (\sigma : \texttt{Subst} \_ \delta). ~ \Delta \equiv (\sigma \triangleleft \Gamma)
\]

\hypertarget{constraint-resolution}{%
\section{Constraint Resolution}\label{constraint-resolution}}


\cite{McBride03}

\paragraph{Constraint Resolution.}

Given a set of accumulated substitutions and some constraints, we will
return (hopefully) some further substitutions, and a set of leftover
constraints to which the substitutions have been applied. These leftover
constraints can either not be simplified or are unsatisfiable. \[
\begin{aligned}
\texttt{solve} &: \texttt{Subst}~\gamma~\delta \times \texttt{List}~(\texttt{Constr}~\delta) \\
&\to \texttt{Subst}~\gamma~\phi \times \texttt{List}~(\texttt{Constr}~\phi)
\end{aligned}
\]

\paragraph{Soundness.}

The simplified constraints are enough to entail the original
constraints. \[
\begin{aligned}
\texttt{solve-sound}
&: \texttt{solve}~(\sigma_1, cs_1) \equiv (\sigma_2, cs_2) \\
&\to \forall (\sigma_f : \texttt{Subst}~\gamma~\delta) \\
& \to [\![ \sigma_f \triangleleft cs_2 ]\!] \to [\![ \sigma_f \cdot \sigma_2 \triangleleft cs_1 ]\!]
\end{aligned}
\]

\paragraph{Completeness.}

Any substitution \(\sigma_f\) that makes the original constraints
\(cs_1\) hold will be a specialisation \(\sigma_f\) of our returned
substitution \(\sigma_2\). The specialisation \(\sigma_g\) will make the
returned constraints \(cs_2\) hold. \[
\begin{aligned}
\texttt{solve-sound}
&: \texttt{solve}~(\sigma_1, cs_1) \equiv (\sigma_2, cs_2) \\
&\to \forall (\sigma_f : \texttt{Subst}~\gamma~\delta). ~ [\![ \sigma_f \triangleleft cs_1 ]\!] \\
&\to \exists (\sigma_g : \sigma_f = \sigma_g \cdot \sigma_2) \times [\![ \sigma_g \triangleleft cs_2 ]\!]
\end{aligned}
\]

\paragraph{Progress.}

Nothing prevents us from returning the original constraints as output.
We therefore promise that every constraint we return is either currently
unsolvable because we have not enough information, or is unsatisfiable
altogether. \[
\begin{aligned}
\texttt{solve-sound}
&: \texttt{solve}~(\sigma_1, cs_1) \equiv (\sigma_2, cs_2) \\
&\to \forall c \in cs_2. ~ \texttt{IsDeferred}~c \uplus \texttt{IsUnsat}~c
\end{aligned}
\] where \[
\texttt{IsUnsat}~c = \forall \sigma. ~ \neg [\![ \sigma \triangleleft c ]\!]
\]

\paragraph{Instantiation.}

\[
\forall c. ~ \texttt{IsDeferred}~c \to \exists \sigma. [\![ \sigma \triangleleft c ]\!]
\]

\bibliographystyle{abbrvnat}
\bibliography{paper}
\end{document}