\documentclass[sigplan,screen,review]{acmart}

\usepackage{todonotes}

% Typing rules
\usepackage{mathpartir}
\mprset {sep=1em} % Horizontal space between premises

\newcommand{\picalc}{$\pi$-calculus}
\newcommand{\Picalc}{$\pi$-Calculus}
\newcommand{\rulename}[1]{{\tiny \textsc{(#1)}}}
\newcommand{\constr}[1]{\textcolor{olive}{\mathtt{#1}}}
\newcommand{\func}[1]{\textcolor{gray}{\mathtt{#1}}}
\newcommand{\type}[1]{\textcolor{blue}{\mathtt{#1}}}

% Syntax types
\newcommand{\Fin}[1]{\type{Fin}~#1}
\newcommand{\fzero}{\constr{zero}}
\newcommand{\fsuc}{\constr{suc}}
\newcommand{\sExpr}[1]{\type{Expr}~#1}
\newcommand{\sProc}[1]{\type{Proc}~#1}
\newcommand{\tvar}[2]{#1 ~\type{\ni_t}~ #2}
\newcommand{\tkind}[2]{#1 ~\type{\vdash_t}~ #2}
\newcommand{\ttype}[1]{\type{Type}~#1}
\newcommand{\tusage}[1]{\type{Usage}~#1}
\newcommand{\tCtx}[2]{\type{Ctx}_{#1}~#2}
\newcommand{\tSplit}[3]{#1~\type{=}~#2~\type{\uplus}~#3}
\newcommand{\tEq}[2]{#1~\type{\equiv}~#2}
\newcommand{\tun}[1]{\type{un}~#1}
\newcommand{\tVar}[3]{#1 ~ \type{\ni} ~ #2 ~ \type{:} ~ #3}
\newcommand{\tExpr}[3]{#1 ~ \type{\vdash} ~ #2 ~ \type{:} ~ #3}
\newcommand{\tProc}[2]{#1 ~ \type{\vdash} ~ #2}
\newcommand{\tConstr}[1]{\type{Constr} ~ #1}
\newcommand{\tConstrs}[1]{\type{[Constr} ~ #1 ~ \type{]}}

% Syntax constructors
\newcommand{\sunit}{\constr{unit}}
\newcommand{\svar}{\constr{var}}
\newcommand{\sfst}{\constr{fst}}
\newcommand{\ssnd}{\constr{snd}}
\newcommand{\sinl}{\constr{inl}}
\newcommand{\sinr}{\constr{inr}}
\newcommand{\spair}{\constr{pair}}
\newcommand{\send}{\constr{end}}
\newcommand{\snew}{\constr{new}}
\newcommand{\scomp}{\constr{comp}}
\newcommand{\srecv}{\constr{recv}}
\newcommand{\ssend}{\constr{send}}
\newcommand{\scase}{\constr{case}}

% Kind constructors
\newcommand{\ktype}{\constr{ty}}
\newcommand{\kusage}{\constr{us}}

% Typing judgment constructors
\newcommand{\tmvar}{\constr{mvar}}
\newcommand{\tchan}{\constr{chan}}
\newcommand{\tunit}{\constr{unit}}
\newcommand{\tsum}{\constr{sum}}
\newcommand{\tprod}{\constr{prod}}
\newcommand{\tzero}{\constr{0\cdot}}
\newcommand{\tone}{\constr{1\cdot}}
\newcommand{\tomega}{\constr{\omega\cdot}}

\newcommand{\subst}[2]{#1 ~ \func{\triangleleft} ~ #2}
\newcommand{\tSubst}[2]{\type{Subst}~#1~#2}
\newcommand{\interpr}[1]{\func{[\![} #1 \func{]\!]}}

% Constraint constructors
\newcommand{\eqconstr}[2]{\constr{[} ~ #1 ~ \constr{\stackrel{c}{=}} ~ #2 ~ \constr{]}}
\newcommand{\sumconstr}[3]{\constr{[} ~ #1 ~ \constr{\stackrel{c}{=}} ~ #2 ~ \constr{+} ~ #3 ~ \constr{]}}

\title
[Co-Contextual Type Inference for the Linear \Picalc{} in Agda]
{Co-Contextual Type Inference \\ for the Linear \Picalc{} \\ in Agda}
\subtitle{(Extended Abstract)}

\author{Uma Zalakain}
\affiliation{University of Glasgow}
\email{u.zalakain.1@research.gla.ac.uk}

\author{Ornela Dardha}
\affiliation{University of Glasgow}
\email{ornela.dardha@glasgow.ac.uk}

\begin{document}

\begin{abstract}
  The linear \picalc{} is a well-known substructural type system for the \picalc{}:
  it is a common target for the encoding of session-typed languages \cite{DardhaGS17},
  and it in direct correspondence with classical linear logic \todo{cite}.

  Type inference for the linear \picalc{} comes with its own challenges:
  for one, processes themselves are untyped, and thus typing constraints only apply to the typing contexts;
  moreover, typing constraints on usage annotations \emph{cannot always be eagerly solved in open processes}.

  We approach the first challenge using \emph{co-contextual type inference} \cite{ErdwegBKKM15}, where processes are traversed bottom-up and constraints are collected (and when possible eagerly solved) and merged on context splits.
  We approach the latter challenge by allowing the resolution of some of the constraints to be deferred.
  We state soundness and completeness theorems that take this deferral of constraint resolution into account.
  We state a progress (?) theorem that shows that only those constraints that need to be deferred are deferred.
  \todo{be more precise}
  We are working on mechanising our work in Agda.
\end{abstract}


\maketitle

\section{Introduction}\label{introduction}

We define an untyped but well scoped \picalc{} using type-level de Bruijn \cite{deBruijn72} indices \autoref{syntax}.
We define a small expression language within the process syntax to handle composite sum and product types.
On top of the well-scoped syntax we provide the standard linear type-system using context-splits \autoref{type-system}.
The type system is indexed by a typing context that admits unsolved metavariables.
These unsolved metavariables are however well kinded: either types or usage annotations.

\todo{insert example showing why we need deferral}

We split typing inference into constraint collection and constraint solving \autoref{inference}.
We start by defining constraints on types and usage annotations \autoref{constraints}
We collect constraints bottom-up, creating extra \emph{merging} constraints on context splits.
This allows type-inference to be easily parallelisable.
We postulate soundness and completeness theorems that allow for constraint solving to be deferred \autoref{inference-theorems}.

(Variables are black, $\type{\textrm{types are blue}}$, $\constr{\textrm{constructors are olive green}}$, $\func{\textrm{functions are gray}}$, and we are sorry this is not a wee poem.)


\section{Syntax}\label{syntax}

Expressions $e_n$ and $f_n$ are of type $\sExpr{n}$, processes $p_n$ and $q_n$ are of type $\sProc{n}$, variable references $i_n$ are of type $\Fin{n}$.
\[
\begin{aligned}[c]
  e_n ~ f_n  :=
  &~ \sunit \\
  |&~ \svar~i_n \\
  |&~ \spair~e_n~f_n \\
  |&~ \sfst~e_n ~|~  \ssnd~e_n \\
  |&~ \sinl~e_n ~|~  \sinr~e_n
\end{aligned}
\begin{aligned}[c]
  p_n ~ q_n  :=
  &~ \send ~|~  \snew~p_{1+n} \\
  |&~ \srecv~e_n~p_{1+n} \\
  |&~ \ssend~e_n~f_n~p_n \\
  |&~ \scomp~p_n~q_n \\
  |&~ \scase~e_n~p_{1+n}~q_{1+n}
\end{aligned}
\]
\todo{add recursion}
\todo{add type assertions}

\section{Type System}\label{type-system}

Both types and usage annotations allow for \emph{holes} or \emph{metavariables}.
We use the same set of metavariables for both types and usage annotations -- this makes their handling more uniform.
We use a context of kinds \(\gamma\) to keep track of whether a metavariable is of type kind $\ktype$ or usage annotation kind $\kusage$: a choice of kind \(k\) in a kinding context \(\gamma\) is denoted as $\tvar{\gamma}{k}$.

We define well kinded types and usage annotations simultaneously so that we are able to provide a uniform unification and context merge algorithm later on (note that we define $\tsum$ and $\tprod$ and $\tzero$, $\tone$ and $\tomega$ in one go to save space):
\begin{mathpar}
  \inferrule {m : \tvar{\gamma}{k}} {\tmvar~m : \tkind{\gamma}{k}}

  \inferrule {
    i : \tkind{\gamma}{\kusage} \\
    o : \tkind{\gamma}{\kusage} \\
    t : \tkind{\gamma}{\ktype}}
  {\tchan~i~o~t : \tkind{\gamma}{\ktype}}

  \inferrule { }
  {\tunit : \tkind{\gamma}{\ktype}}

  \inferrule {s : \tkind{\gamma}{\ktype} \\ t : \tkind{\gamma}{\ktype} }
  {\tsum~s~t ~|~ \tprod~s~t : \tkind{\gamma}{\ktype}}

  \inferrule { } {\tzero ~|~ \tone ~|~ \tomega : \tkind{\gamma}{\kusage}}
\end{mathpar}
We will henceforth use $\ttype{\gamma}$ to stand for $\tkind{\gamma}{\ktype}$ and $\tusage{\gamma}$ to stand for $\tkind{\gamma}{\kusage}$.

A context $\Gamma$ of type $\tCtx{n}{\gamma}$ is a list of $\ttype{\gamma}$ of size $n$.
We define context splits $\tSplit{\Gamma}{\Delta}{\Theta}$ pointwise on types.
Splits on types are defined pointwise recursively on usage annotations -- note however that only the usage annotations on the top level of a channel (that is, not within its payload) are split.
Splits on usage annotations are defined as follows -- note that they are not necessarily unique:
\begin{mathpar}
  \inferrule { } {\tSplit{x}{x}{\tzero}}

  \inferrule { } {\tSplit{x}{\tzero}{x}}

  \inferrule { } {\tSplit{\tomega}{x}{y}}
\end{mathpar}
\todo{generalisation to an algebra?}

A usage annotation $x$, type $t$ or context $\Gamma$ is unrestricted (shared, non-linear) $\tun{\Gamma}$ if it can be split into itself: $\tSplit{\Gamma}{\Gamma}{\Gamma}$ (respectively $x$ and $t$) \cite{Padovani15}.

We can finally define our typing judgment for variables, expressions and processes -- some are omitted for brevity.

\begin{mathpar}
%  \inferrule { \Gamma : \tCtx{n}{\gamma} \\ i : \Fin{n} \\ t : \ttype{\gamma} }
%             { \tVar{\Gamma}{i}{t} }

  \inferrule { \Gamma : \tCtx{n}{\gamma} \\ \tun{\Gamma} \\ t : \ttype{\gamma} }
             { \tVar{\Gamma,t}{\fzero}{t} }
             \rulename{zero}

  \inferrule { \tVar{\Gamma}{i}{t} \\ s : \ttype{\gamma} \\ \tun{s} }
             { \tVar{\Gamma,s}{\fsuc~i}{t} }
             \rulename{suc}

%  \inferrule { \Gamma : \tCtx{n}{\gamma} \\ e : \sExpr{n} \\ t : \ttype{\gamma}}
%             { \tExpr{\Gamma}{e}{t} }

  \inferrule { \tVar{\Gamma}{i}{t} } { \tExpr{\Gamma}{\svar~i}{t} } \rulename{var}

  \inferrule { \tun{\Gamma} } { \tExpr{\Gamma}{\sunit}{\tunit} } \rulename{unit}

  \inferrule { \tExpr{\Gamma}{e}{\tprod~t~s} \\ \tun{s}} { \tExpr{\Gamma}{\sfst~e}{t}} \rulename{fst}

  \inferrule { \tExpr{\Gamma}{e}{t} } { \tExpr{\Gamma}{\sinl~e}{\tsum~t~s}} \rulename{inl}

  \inferrule { \tSplit{\Gamma}{\Delta}{\Theta} \\ \tExpr{\Delta}{e}{s} \\ \tExpr{\Theta}{f}{t} }
             { \tExpr{\Gamma}{\spair~e~f}{\tprod~s~t}}
             \rulename{pair}

%  \inferrule { \Gamma : \tCtx{n}{\gamma} \\ p : \sProc{n}}
%             { \tProc{\Gamma}{p} }

  \inferrule { \tun{\Gamma} } { \tProc{\Gamma}{\send} } \rulename{end}

  \inferrule { t : \ttype{\gamma} \\ \tProc{\Gamma , t}{p} } { \tProc{\Gamma}{\snew~p} }
             \rulename{new}

  \inferrule { \tSplit{\Gamma}{\Delta}{\Theta} \\ \tExpr{\Delta}{e}{\tchan~\tone~\tzero~t} \\ \tProc{\Theta,t}{p} }
             { \tProc{\Gamma}{\srecv~e~p} }
             \rulename{recv}

  \inferrule { \tSplit{\Gamma}{\Delta}{\Theta} \\ \tExpr{\Delta}{e}{\tsum~s~t} \\ \tProc{\Theta,s}{p} \\ \tProc{\Theta,t}{q} }
             { \tProc{\Gamma}{\scase~e~p~q} }
             \rulename{case}
\end{mathpar}

     
\section{Inference}\label{inference}

Co-contextual type inference traverses processes bottom up collecting constraints.
Limiting the information flow to being bottom up has the advantage of making inference subproblems independent and thus easily parallelisable.
For the shared \picalc{}, inference constraints amount to unification problems that can always be eagerly solved.
The linear \picalc{} however requires that some constraints are deferred to a later stage, when more information is available.

Let us suppose we can safely instantiate to $\tzero$ every usage annotation that is unrestricted.
Consider the open process $\ssend~a~\sunit~(\ssend~x~a~\send)$ where $x$ and $a$ are free: we send the unit over $a$, then send $a$ over $x$ and terminate.
By the time we reach $\send$ both $x$ and $a$ must be unrestricted, and thus channel $x$ must be of some type $\tchan~\tzero~\tone~t$.
Since we send a unit over $a$, $a$ must be of some type $s$ such that $\tSplit{s}{\tchan~\tzero~\tone~\tunit}{t}$.
From this we can infer that both $s$ and $t$ must be a channel type and thus $\tSplit{s_i}{\tzero}{t_i}$ and $\tSplit{s_o}{\tone}{t_o}$ for some $s_i$, $t_i$, $s_o$ and $t_o$, but we cannot infer their usage annotations: all we can deduce is their lower bounds $\tzero$ and $\tone$.
We must defer the resolution of these constraints until more information becomes available about the context of this open process.

We present two kinds of constraints, showcase how to encode inference problems for some of the typing rules in \autoref{type-system}, and state the lemmas that will allow us to show that our approach to inference is both sound and complete.

\paragraph{Constraints}

Constraints are of type $\tConstr{\gamma}$ and are defined on arguments of type $\tkind{\gamma}{k}$ for some $k$ --- that is, both usage annotations and types.
They take two forms: the binary $\eqconstr{S}{T}$, where $S$ and $T$ are meant to be unified, and the ternary $\sumconstr{S}{T}{R}$, where $T$ and $R$ are meant to be added up to $S$.
Constraints of the former form can \emph{always} be eagerly solved, while constraints of the latter \emph{sometimes} cannot, and must be deferred.
We use $\tConstrs{\gamma}$ to refer to lists of constraints of type $\tConstr{\gamma}$.

\paragraph{Substitution}

\todo{Introduce Subst type}

We encode substitution as a function $\subst{\_}{\_}$ of type $(\forall k \to \tvar{\gamma}{k} \to \tkind{\delta}{k}) \to (\forall k \to \tkind{\gamma}{k} \to \tkind{\delta}{k})$ that acts on usage annotations and types and typing contexts, and that freely alters the metavariable context.
We define substitutions on constraints pointwise on their arguments.

\paragraph{Constraint satisfaction}

We use a $\interpr{\_}$ function to interpret constraints $\eqconstr{S}{T}$ and $\sumconstr{S}{T}{R}$ into their proof counterparts $\tEq{S}{T}$ and $\tSplit{S}{T}{R}$.

\paragraph{Inference}

We encode type inference as a function taking processes with $n$ free variables and returning a metavariable context $\gamma$, a typing context with $n$ free variables containing metavariables in $\gamma$, and a list of constraints on those metavariables $\gamma$:
$$
\func{inferProc} : \sProc{n} \to ~ \exists \gamma. ~ \tCtx{n}{\gamma} \times \tConstrs{\gamma}
$$
We define a similar function for type inference on expressions, this time also returning a type $\tau$ of type $\ttype{\gamma}$ for the expression.
$$
\func{inferExpr} : \sExpr{n} \to ~ \exists \gamma. ~ \tCtx{n}{\gamma} \times \ttype{\gamma} \times \tConstrs{\gamma}
$$
This functions are total: if processes and expressions are untypable, their constraints will simply be unsolvable.
Let us provide a couple of examples illustrating how this function is defined:
\begin{itemize}
\item
  For the expression $\sfst~e$ we first recursively infer $e$: $\func{inferExpr}~e = \gamma,\Gamma,\tau,Cs$.
  We then add two fresh metavariables $?t$ and $?s$ of kind $\ktype$ to $\gamma$, add constraints $\eqconstr{\tau}{\tprod~?t~?s}$ and $\sumconstr{?s}{?s}{?s}$ to $cs$, then return $?t$ as the type of $e$.

\item
  For the expression $\scase~e~p~q$ we first recursively infer $p$ and $q$ and $e$: $\func{inferProc}~p = \theta_p, (\Theta_p, s) , Cs_p$, $\func{inferProc}~q = \theta_q, (\Theta_q, t) , Cs_q$, and $\func{inferExpr}~e = \delta_e, \Delta_e, \tau, Cs_e$.
  We create a new metavariable context $\gamma$ and a new typing context $\Gamma$ where every type is a fresh metavariable in $\gamma$.
  We take the union of the metavariables in $\gamma$, $\theta_p$, $\theta_q$ and $\delta_e$
  We take the union of the constraints in $Cs_p$, $Cs_q$ and $Cs_e$, and create new constraints $\eqconstr{\Theta_p}{\Theta_q}$, $\sumconstr{\Gamma}{\Delta_e}{\Theta_p}$, and $\eqconstr{\tau}{\tsum~s~t}$ and return $\Gamma$ as the inferred context.
\end{itemize}

\paragraph{Inference soundness.}

Every substitution \(\sigma\) that makes the constraints hold will make the process typable under the substituted context.
\begin{flalign*}
& \tEq{\func{infer}~p}{\gamma , \Gamma , cs} \to (\sigma : \tSubst{\gamma}{\delta}) \to \interpr{\subst{\sigma}{cs}} \to \tProc{(\subst{\sigma}{\Gamma})}{p} &&
\end{flalign*}

\paragraph{Inference completeness.}

For every context \(\Delta\) that makes the process typable there exists a most general substitution \(\sigma\) that will solve the constraints and which substitutes in \(\Gamma\) to something more general than \(\Delta\).
\begin{flalign*}
& \tEq{\func{infer}~p}{\gamma , \Gamma , cs} \to (\Delta : \tCtx{n}{\gamma}) \to \tProc{\Delta}{p} && \\
&\to \exists \delta. ~ \exists (\sigma : \texttt{Subst}~\gamma~\delta). \interpr{\subst{\sigma}{cs}} \times (\tProc{\subst{\sigma}{\Gamma}}{p}) \times \Delta \subseteq (\subst{\sigma}{\Gamma}) &&
\end{flalign*}
where $$
\Delta \func{\subseteq} \Gamma \triangleq \exists \delta. ~ \exists (\sigma : \tSubst{\_}{\delta}). ~ \tEq{\Delta}{(\subst{\sigma}{\Gamma})}
$$

\section{Constraint Resolution}\label{constraint-resolution}


\cite{McBride03}

\paragraph{Constraint Resolution.}

Given a set of accumulated substitutions and some constraints, we will
return (hopefully) some further substitutions, and a set of leftover
constraints to which the substitutions have been applied. These leftover
constraints can either not be simplified or are unsatisfiable. \[
\begin{aligned}
\func{solve} &: \tConstrs{\gamma} \to \tSubst{\gamma}{\delta} \times \tConstrs{\delta}
\end{aligned}
\]

\paragraph{Soundness.}

The simplified constraints are enough to entail the original constraints.
\[
\begin{aligned}
& ~ \tEq{\func{solve}~cs_1}{(\sigma, cs_2)} \to (\sigma_f : \tSubst{\gamma}{\delta}) \\
\to& \interpr{\subst{\sigma_f}{cs_2}} \to \interpr{\subst{\sigma_f \cdot \sigma}{cs_1}}
\end{aligned}
\]

\paragraph{Completeness.}

Any substitution \(\sigma_f\) that makes the original constraints \(cs_1\) hold will be a specialisation \(\sigma_f\) of our returned substitution \(\sigma_2\). The specialisation \(\sigma_g\) will make the returned constraints \(cs_2\) hold.
\begin{flalign*}
&\tEq{\func{solve}~cs_1}{(\sigma, cs_2)} \to (\sigma_f : \tSubst{\gamma}{\delta}) \to \interpr{\subst{\sigma_f}{cs_1}} && \\
&\to \exists (\sigma_g : \tSubst{\_}{\delta}). ~ \tEq{\sigma_f}{\sigma_g \cdot \sigma} \times \interpr{\subst{\sigma_g}{cs_2}} &&
\end{flalign*}

\paragraph{Progress.}

Nothing prevents us from returning the original constraints as output.
We therefore promise that every constraint we return is either currently
unsolvable because we have not enough information, or is unsatisfiable
altogether.
\begin{flalign*}
&\func{solve}~cs_1 \equiv (\sigma, cs_2) \to \forall c \in cs_2. ~ \type{IsDeferred}~c ~ \type{\uplus} ~ \type{IsUnsat}~c &&
\end{flalign*}
where
\begin{flalign*}
& \type{IsUnsat}~c \triangleq \forall \sigma. ~ \neg \interpr{\subst{\sigma}{c}} &&
\end{flalign*}

\paragraph{Instantiation.}

\begin{flalign*}
& \forall c. ~ \type{IsDeferred}~c \to \exists \sigma. \interpr{\subst{\sigma}{c}} &&
\end{flalign*}

\bibliographystyle{abbrvnat}
\bibliography{paper}
\end{document}