\documentclass[sigplan,screen,review]{acmart}

\usepackage[inline]{enumitem}
\usepackage{todonotes}

\renewcommand*{\sectionautorefname}{\S\!\!\,}
\renewcommand*{\subsectionautorefname}{\S\!\!\,}

% Typing rules
\usepackage{mathpartir}
\mprset {sep=0.5em} % Horizontal space between premises

\newcommand{\picalc}{$\pi$-calculus}
\newcommand{\Picalc}{$\pi$-Calculus}
\newcommand{\rulename}[1]{{\tiny \textsc{(#1)}}}
\newcommand{\constr}[1]{\textcolor{olive}{\mathtt{#1}}}
\newcommand{\func}[1]{\textcolor{gray}{\mathtt{#1}}}
\newcommand{\type}[1]{\textcolor{blue}{\mathtt{#1}}}

% Syntax types
\newcommand{\Fin}[1]{\type{Fin}~#1}
\newcommand{\fzero}{\constr{zero}}
\newcommand{\fsuc}{\constr{suc}}
\newcommand{\sExpr}[1]{\type{Expr}~#1}
\newcommand{\sProc}[1]{\type{Proc}~#1}
\newcommand{\tvar}[2]{#1 ~\type{\ni_t}~ #2}
\newcommand{\tkind}[2]{#1 ~\type{\vdash_t}~ #2}
\newcommand{\ttype}[1]{\type{Type}~#1}
\newcommand{\tusage}[1]{\type{Usage}~#1}
\newcommand{\tCtx}[2]{\type{Ctx}_{#1}~#2}
\newcommand{\tSplit}[3]{#1~\type{=}~#2~\type{\uplus}~#3}
\newcommand{\tEq}[2]{#1~\type{\equiv}~#2}
\newcommand{\tun}[1]{\type{un}~#1}
\newcommand{\tVar}[3]{#1 ~ \type{\ni} ~ #2 ~ \type{:} ~ #3}
\newcommand{\tExpr}[3]{#1 ~ \type{\vdash} ~ #2 ~ \type{:} ~ #3}
\newcommand{\tProc}[2]{#1 ~ \type{\vdash} ~ #2}
\newcommand{\tConstr}[1]{\type{Constr} ~ #1}
\newcommand{\tConstrs}[1]{\type{[Constr} ~ #1 ~ \type{]}}

% Syntax constructors
\newcommand{\sunit}{\constr{unit}}
\newcommand{\svar}{\constr{var}}
\newcommand{\sfst}{\constr{fst}}
\newcommand{\ssnd}{\constr{snd}}
\newcommand{\sinl}{\constr{inl}}
\newcommand{\sinr}{\constr{inr}}
\newcommand{\spair}{\constr{pair}}
\newcommand{\send}{\constr{end}}
\newcommand{\snew}{\constr{new}}
\newcommand{\scomp}{\constr{comp}}
\newcommand{\srecv}{\constr{recv}}
\newcommand{\ssend}{\constr{send}}
\newcommand{\scase}{\constr{case}}
\newcommand{\srec}{\constr{rec}}

% Kind constructors
\newcommand{\ktype}{\constr{ty}}
\newcommand{\kusage}{\constr{us}}

% Typing judgment constructors
\newcommand{\tmvar}{\constr{mvar}}
\newcommand{\tchan}{\constr{chan}}
\newcommand{\tunit}{\constr{unit}}
\newcommand{\tsum}{\constr{sum}}
\newcommand{\tprod}{\constr{prod}}
\newcommand{\tzero}{\constr{0\cdot}}
\newcommand{\tone}{\constr{1\cdot}}
\newcommand{\tomega}{\constr{\omega\cdot}}

\newcommand{\subst}[2]{#1 ~ \func{\triangleleft} ~ #2}
\newcommand{\tSubst}[2]{\type{Subst}~#1~#2}
\newcommand{\interpr}[1]{\func{[\![} #1 \func{]\!]}}

% Constraint constructors
\newcommand{\eqconstr}[2]{\constr{[} ~ #1 ~ \constr{\stackrel{c}{=}} ~ #2 ~ \constr{]}}
\newcommand{\sumconstr}[3]{\constr{[} ~ #1 ~ \constr{\stackrel{c}{=}} ~ #2 ~ \constr{+} ~ #3 ~ \constr{]}}

\title
[Co-Contextual Typing Inference for the Linear \Picalc{} in Agda]
{Co-Contextual Typing Inference \\ for the Linear \Picalc{} in Agda}
\subtitle{(Extended Abstract)}

\author{Uma Zalakain}
\affiliation{University of Glasgow}
\email{u.zalakain.1@research.gla.ac.uk}

\author{Ornela Dardha}
\affiliation{University of Glasgow}
\email{ornela.dardha@glasgow.ac.uk}

\begin{document}

\begin{abstract}
  To type check a \picalc{} with linear and shared types without relying on type annotations, newly created channels must have their types inferred.
  However, processes can partially use a channel and then send it away: in this case, the receiving process might further constraint its inferred type.
  This results in non-local constraints that do not have a most general unifier but have to be kept around.

  Following \cite{Padovani15}, we provide a \emph{co-contextual typing inference} \cite{ErdwegBKKM15} algorithm that traverses processes bottom-up collecting constraints.
  We then solve (some of) these constraints using well-known unification algorithms \cite{McBride03} to find the most general unifier, and defer those that do not have one.
  We state clear soundness and completeness theorems for both these stages and a progress theorem that ensures that only constraints without a most general unifier are deferred.
  The totality of this work is being mechanised in Agda.
\end{abstract}


\maketitle

\section{Introduction}\label{introduction}

The \picalc{} \todo{cite} models concurrent processing by boiling down process interaction to the transmission of data over communication channels --- where channels too are sent as payload.
The linear \picalc{} \todo{cite} introduces a type system that ensures that every channel is used \emph{exactly} once.
This restriction ensures communication privacy, communication safety, and the absence of race conditions.
We generalise and admit a \picalc{} where the input and output multiplicities of a channel are either $0$ (cannot be used), $1$ (must be used exactly once), or $\omega$ (unrestricted use).

To type check a \picalc{} process with shared and linear types we must assign a type to every communication channel created within the process.
To do so we can either ask the user for type annotations \todo{cite}, or try to synthesize these types by looking at how the channels are used.
The latter approach involves dealing with non-local constraints: a channel can be partially used and then sent away --- the process that receives it might further constrain its type.
This means that only those constraints with a most general solution can safely be eagerly solved, otherwise we risk over-constraining down the line.
We use co-contextual typing inference \cite{ErdwegBKKM15} to infer a typing context and gather constraints as we traverse processes bottom-up.
Typing constraints with a most general unifier are eagerly solved and result in substitutions on the typing context, the remaining typing constraints is carried along.
Collecting constraints bottom-up has the additional advantage of making typing inference easily parallelisable.
Empowered with a typing inference algorithm that for a process $P$ infers the most general typing context $\Gamma$ and some typing constraints, checking that $\Delta \vdash P$ for some $\Delta$ amounts to emitting the extra constraint $\Gamma = \Delta$.

To the best of our knowledge, this problem is only treated in Padovani's work on type reconstruction for composite types \cite{Padovani15}.
However, his work does not appear to be mechanised, and metatheoretical properties like soundness and completeness are only informally addressed.
With this work, we aim to:
\begin{itemize}
  \item State and prove clear soundness and completeness theorems for both constraint collection (\autoref{constraint-collection}) and constraint resolution (\autoref{constraint-resolution}).
  \item Mechanise in Agda the totality of this work.
\end{itemize}

We start defining an untyped but well scoped \picalc{} using type-level de Bruijn indices \cite{deBruijn72} and embed a small expression language that handles composite sum and product types.
On top, we define a standard type system with linear and shared types using context-splits.
We then provide an overview of how type inference works, show how constraint collection (\autoref{constraint-collection}) and constraint resolution (\autoref{constraint-resolution}) are defined, and state that both phases are sound and complete with regards to the previously defined type system.

We have proven that constraint collection is sound, and that equality constraint resolution is sound (adapting McBride's work \cite{McBride03} to deal with intrinsically kinded terms).
The remainder proofs are still in progress. 

(Note on notation: variables are black, \textcolor{blue}{types are blue}, \textcolor{olive}{constructors are green}, \textcolor{gray}{functions are gray}, and we are sorry this is not a poem.)


\section{Type System}

We define a standard syntax and type system for the linear \picalc{}.
The only non-standard feature is that types allow for \emph{metavariables} (\emph{holes}) within them.

\paragraph{Syntax}
\label{syntax}

We define a standard syntax for the \picalc{} using type-level de Bruijn indices.
Variable references $i_n$ are of type $\Fin{n}$, expressions $e_n$ and $f_n$ are of type $\sExpr{n}$, processes $p_n$ and $q_n$ are of type $\sProc{n}$.
\todo{add type assertions}
\[
\begin{aligned}[c]
  e_n ~ f_n  :=
  &~ \sunit \\
  |&~ \svar~i_n \\
  |&~ \spair~e_n~f_n \\
  |&~ \sfst~e_n ~|~  \ssnd~e_n \\
  |&~ \sinl~e_n ~|~  \sinr~e_n
\end{aligned}
\begin{aligned}[c]
  p_n ~ q_n  :=
  &~ \send ~|~  \srec~p_n ~|~ \snew~p_{1+n} \\
  |&~ \srecv~e_n~p_{1+n} \\
  |&~ \ssend~e_n~f_n~p_n \\
  |&~ \scomp~p_n~q_n \\
  |&~ \scase~e_n~p_{1+n}~q_{1+n} \\
\end{aligned}
\]

\paragraph{Types}
\label{types}


Both types and usage annotations contain \emph{metavariables} (\emph{holes}).
We use a common set of metavariables for both types and usage annotations -- this makes their handling uniform.
A context of kinds \(\gamma\) keeps track of whether a metavariable is of type kind $\ktype$ or usage annotation kind $\kusage$.
We refer to a metavariable of kind \(k\) in a kinding context \(\gamma\) as $\tvar{\gamma}{k}$.
We can now define usage annotations and types in one go (note that we define $\tsum$ and $\tprod$ together for brevity):
\begin{mathpar}
  \inferrule {m : \tvar{\gamma}{k}} {\tmvar~m : \tkind{\gamma}{k}}

  \inferrule {
    i : \tkind{\gamma}{\kusage} \\
    o : \tkind{\gamma}{\kusage} \\
    t : \tkind{\gamma}{\ktype}}
  {\tchan~i~o~t : \tkind{\gamma}{\ktype}}

  \inferrule { }
  {\tunit : \tkind{\gamma}{\ktype}}

  \inferrule {s : \tkind{\gamma}{\ktype} \\ t : \tkind{\gamma}{\ktype} }
  {\tsum~s~t ~|~ \tprod~s~t : \tkind{\gamma}{\ktype}}

  \inferrule { } {\tzero : \tkind{\gamma}{\kusage}}

  \inferrule { } {\tone : \tkind{\gamma}{\kusage}}

  \inferrule { } {\tomega : \tkind{\gamma}{\kusage}}
\end{mathpar}
For convenience we henceforth use $\ttype{\gamma}$ to stand for $\tkind{\gamma}{\ktype}$ and $\tusage{\gamma}$ to stand for $\tkind{\gamma}{\kusage}$.

\paragraph{Context Splits}
\label{types}
A context $\Gamma$ of type $\tCtx{n}{\gamma}$ is a list of $\ttype{\gamma}$ of size $n$.
We define context splits $\tSplit{\Gamma}{\Delta}{\Theta}$ pointwise on types.
Splits on types are defined recursively pointwise on usage annotations -- note however that only the usage annotations on the top level of a channel (that is, not within its payload) are split.
Splits on usage annotations are defined as follows -- note that they are not necessarily unique:
\begin{mathpar}
  \inferrule { } {\tSplit{x}{x}{\tzero}}

  \inferrule { } {\tSplit{x}{\tzero}{x}}

  \inferrule { } {\tSplit{\tomega}{x}{y}}
\end{mathpar}
Following \cite{Padovani15}, we say a context $\Gamma$ is unrestricted (shared, non-linear) $\tun{\Gamma}$ if it can be split into itself: $\tSplit{\Gamma}{\Gamma}{\Gamma}$ --- (similarly $\tun{x}$ and $\tun{t}$ for usage annotations $x$ and types $t$, respectively).

\paragraph{Typing Judgments}
\label{typing-judgments}
We can finally define our typing judgment for variables, expressions and processes -- some are omitted for brevity.

\begin{mathpar}
%  \inferrule { \Gamma : \tCtx{n}{\gamma} \\ i : \Fin{n} \\ t : \ttype{\gamma} }
%             { \tVar{\Gamma}{i}{t} }

  \inferrule { \Gamma : \tCtx{n}{\gamma} \\ \tun{\Gamma} \\ t : \ttype{\gamma} }
             { \tVar{\Gamma,t}{\fzero}{t} }
             % \rulename{zero}

  \inferrule { \tVar{\Gamma}{i}{t} \\ s : \ttype{\gamma} \\ \tun{s} }
             { \tVar{\Gamma,s}{\fsuc~i}{t} }
             % \rulename{suc}

%  \inferrule { \Gamma : \tCtx{n}{\gamma} \\ e : \sExpr{n} \\ t : \ttype{\gamma}}
%             { \tExpr{\Gamma}{e}{t} }

  \inferrule { \tVar{\Gamma}{i}{t} } { \tExpr{\Gamma}{\svar~i}{t} }
             % \rulename{var}

  \inferrule { \tun{\Gamma} } { \tExpr{\Gamma}{\sunit}{\tunit} }
             % \rulename{unit}

  \inferrule { \tExpr{\Gamma}{e}{\tprod~t~s} \\ \tun{s}} {\tExpr{\Gamma}{\sfst~e}{t}}
             % \rulename{fst}

  \inferrule { \tExpr{\Gamma}{e}{t} } { \tExpr{\Gamma}{\sinl~e}{\tsum~t~s}}
             % \rulename{inl}

  \inferrule { \tSplit{\Gamma}{\Delta}{\Theta} \\ \tExpr{\Delta}{e}{s} \\ \tExpr{\Theta}{f}{t} }
             { \tExpr{\Gamma}{\spair~e~f}{\tprod~s~t}}
             %\rulename{pair}

%  \inferrule { \Gamma : \tCtx{n}{\gamma} \\ p : \sProc{n}}
%             { \tProc{\Gamma}{p} }

  \inferrule { \tun{\Gamma} } { \tProc{\Gamma}{\send} }
             %\rulename{end}

  \inferrule { \tProc{\Gamma}{p} \\ \tun{\Gamma} }
             { \tProc{\Gamma}{\srec~p} }
             %\rulename{rec}

  \inferrule { t : \ttype{\gamma} \\ \tProc{\Gamma , t}{p} } { \tProc{\Gamma}{\snew~p} }
             %\rulename{new}

  \inferrule { \tSplit{\Gamma}{\Delta}{\Theta} \\ \tExpr{\Delta}{e}{\tchan~\tone~\tzero~t} \\ \tProc{\Theta,t}{p} }
             { \tProc{\Gamma}{\srecv~e~p} }
             %\rulename{recv}

  \inferrule { \tSplit{\Gamma}{\Delta}{\Theta} \\ \tExpr{\Delta}{e}{\tsum~s~t} \\ \tProc{\Theta,s}{p} \\ \tProc{\Theta,t}{q} }
             { \tProc{\Gamma}{\scase~e~p~q} }
             %\rulename{case}
\end{mathpar}

     
\section{Inference}\label{inference}

Co-contextual type inference traverses processes bottom-up collecting constraints.
This has the advantage of making inference subproblems independent and thus easily parallelisable.
In the shared \picalc{}, inference constraints always have a most general unifier, in the shared \emph{and} linear \picalc{} however they do not.
Consider the open process $\ssend~a~\sunit~(\ssend~x~a~\send)$ where $x$ and $a$ are free: we use part of $a$ to send a unit, then send $a$ away over $x$ and terminate.
When the process terminates, all multiplicities must be unrestricted, but we cannot decide whether a multiplicity must be instantiated to $0$ or to $\omega$.
Similarly, we cannot know \emph{how much} of $a$ we are sending away over $x$: that depends on what the receiving process does with $a$.
However, we have to keep track of the fact that $a$ has been used once to send.

In \autoref{constraint-collection} we introduce typing constraints, define kind-preserving substitution and constraint satisfaction, and provide a typing inference algorithm.
We show that satisfying the constraints generated by typing inference is enough to make a process typable (soundness), and postulate that for any typable process typing inference will find the most general set of constraints that makes the process typable (completeness).

In \autoref{constraint-resolution} we solve equality constraints by unification and context split constraints by decomposition.
Constraints have either no solution, a most general solution, or multiple possible solutions.
(Committing to a solution that is not the most general can prove to be the wrong choice in an open process, and thus we avoid doing so.
Closed processes can have solutions that are not the most general safely instantiated.)
Solving a set of constraints results in a set of substitutions and a set of simplified constraints where those substitutions have already been performed.
We postulate that satisfying the simplified constraints amounts to satisfying the original constraints after substitution (soundness), and that for every substitution that solves the original constraints we can find a most general substitution that will solve the simplified constraints (completeness).
Additionally, we postulate that the simplified set of constraints only contains constraints that are either unsatisfiable or not the most general.

\subsection{Constraint Collection}
\label{constraint-collection}

\paragraph{Constraints}

Constraints of type $\tConstr{\gamma}$ are defined on arguments of type $\tkind{\gamma}{k}$ for some $k$ --- that is, both usage annotations and types.
They take two forms: the binary $\eqconstr{S}{T}$, where $S$ and $T$ are meant to be unified, and the ternary $\sumconstr{S}{T}{R}$, where $T$ and $R$ are meant to be added up to $S$.
Constraints of the former form can \emph{always} be eagerly solved, while constraints of the latter can \emph{sometimes} not, and must be deferred.
We use $\tConstrs{\gamma}$ to refer to lists of constraints of type $\tConstr{\gamma}$.

\paragraph{Substitution}

A kind-preserving substitution $\tSubst{\gamma}{\delta}$ maps usage annotation and type metavariables in $\gamma$ to usage annotations and types in $\delta$, that is, $\forall k \to \tvar{\gamma}{k} \to \tkind{\delta}{k}$.
The function $\subst{\sigma}{t}$ of type $\tSubst{\gamma}{\delta} \to (\forall k \to \tkind{\gamma}{k} \to \tkind{\delta}{k})$ performs the substitution by replacing all the metavariables in $t$ with their corresponding terms in $\sigma$.
Substitutions on constraints are defined pointwise on their arguments.



\paragraph{Constraint Satisfaction}

We use a $\interpr{\_}$ function to interpret constraints $\eqconstr{S}{T}$ and $\sumconstr{S}{T}{R}$ into their proof counterparts $\tEq{S}{T}$ and $\tSplit{S}{T}{R}$.

\paragraph{Inference}

% Context splits are solved by creating an extra fresh context together with constraints that bind the three.
% 
We encode type inference as a function that takes processes with $n$ free variables and returns a metavariable context $\gamma$, a typing context with $n$ free variables containing metavariables in $\gamma$, and a list of constraints on those metavariables $\gamma$.
We define a similar function for type inference on expressions, this time also returning a type $\tau$ of type $\ttype{\gamma}$ for the expression:
\begin{flalign*}
& \func{inferProc} : \sProc{n} \to ~ \exists \gamma. ~ \tCtx{n}{\gamma} \times \tConstrs{\gamma} && \\
& \func{inferExpr} : \sExpr{n} \to ~ \exists \gamma. ~ \tCtx{n}{\gamma} \times \tConstrs{\gamma} \times \ttype{\gamma} &&
\end{flalign*}
These functions are total: if processes and expressions are untypable, their constraints will simply be unsolvable.
Let us provide a couple of examples illustrating how this function is defined:

For the expression $\sfst~e$ we first recursively infer $e$: $\func{inferExpr}~e = \gamma,\Gamma,Cs,\tau$.
We then add two fresh metavariables $?t$ and $?s$ of kind $\ktype$ to $\gamma$, add constraints $\eqconstr{\tau}{\tprod~?t~?s}$ and $\sumconstr{?s}{?s}{?s}$ to $cs$, then return $?t$ as the type of $e$.

For the expression $\scase~e~p~q$ we first recursively infer $p$ and $q$ and $e$: $\func{inferProc}~p = \theta_p, (\Theta_p, s) , Cs_p$, $\func{inferProc}~q = \theta_q, (\Theta_q, t) , Cs_q$, and $\func{inferExpr}~e = \delta_e, \Delta_e, Cs_e, \tau$.
We create a new metavariable context $\gamma$ and a new typing context $\Gamma$ where every type is a fresh metavariable in $\gamma$.
We take the union of the metavariables in $\gamma$, $\theta_p$, $\theta_q$ and $\delta_e$
We take the union of the constraints in $Cs_p$, $Cs_q$ and $Cs_e$, and create new constraints $\eqconstr{\Theta_p}{\Theta_q}$, $\sumconstr{\Gamma}{\Delta_e}{\Theta_p}$, and $\eqconstr{\tau}{\tsum~s~t}$ and return $\Gamma$ as the inferred context.

\paragraph{Inference Soundness}

Every substitution \(\sigma\) that makes the constraints hold will make the process typable under the substituted context. Given $\tEq{\func{infer}~p}{\gamma , \Gamma , cs}$ we have that:
\begin{flalign*}
& (\sigma : \tSubst{\gamma}{\delta}) \to \interpr{\subst{\sigma}{cs}} \to \tProc{(\subst{\sigma}{\Gamma})}{p} &&
\end{flalign*}

\paragraph{Inference Completeness}

For every context \(\Delta\) that makes the process typable there exists a most general substitution \(\sigma\) that will solve the constraints and which substitutes in \(\Gamma\) to something more general than \(\Delta\).
We define $\Delta ~ \func{\subseteq} ~ \Gamma$ as $\exists \delta. ~ \exists (\sigma : \tSubst{\_}{\delta}). ~ \tEq{\Delta}{(\subst{\sigma}{\Gamma})}$.
Given $\tEq{\func{infer}~p}{\gamma , \Gamma , cs}$ we have that:
\begin{flalign*}
  &(\Delta : \tCtx{n}{\gamma}) \to \tProc{\Delta}{p} \to && \\
  & \exists \delta. ~ \exists (\sigma : \tSubst{\gamma}{\delta}). ~ \interpr{\subst{\sigma}{cs}} \times \Delta \subseteq (\subst{\sigma}{\Gamma}) &&
\end{flalign*}

\subsection{Constraint Resolution}
\label{constraint-resolution}

Solving a set of constraints results in a set of substitutions and an unsolved set of simplified constraints where those substitutions have already been performed.
Simplified constraints have either no solution, or multiple possible solutions.
Constraints of the form $\eqconstr{x}{y}$ are solved by unification using a kinded version of McBride's unification by structural recursion \cite{McBride03}, and have either no solution, or a most general solution that results in a substitution.
Constraints of the form $\sumconstr{x}{y}{z}$ are solved recursively until a base case is reached, at which point they either have a most general solution or not.
$$
\begin{aligned}
\func{solve} &: \tConstrs{\gamma} \to \tSubst{\gamma}{\delta} \times \tConstrs{\delta}
\end{aligned}
$$

\paragraph{Resolution Soundness}

Satisfying the simplified constraints satisfies the original constraints once substitutions are applied: $\tEq{\func{solve}~cs_1}{(\sigma, cs_2)}$ we have that:
\[
\begin{aligned}
& (\sigma_f : \tSubst{\gamma}{\delta}) \to \interpr{\subst{\sigma_f}{cs_2}} \to \interpr{\subst{\sigma_f \cdot \sigma}{cs_1}}
\end{aligned}
\]

\paragraph{Resolution Completeness}

Any substitution \(\sigma_f\) that makes the original constraints \(cs_1\) hold will be a specialisation \(\sigma_g\) of the returned substitution \(\sigma\).
The specialisation \(\sigma_g\) makes the returned constraints \(cs_2\) hold.
Given $\tEq{\func{solve}~cs_1}{(\sigma, cs_2)}$ we have that:
\begin{flalign*}
&(\sigma_f : \tSubst{\gamma}{\delta}) \to \interpr{\subst{\sigma_f}{cs_1}} \to && \\
&\exists (\sigma_g : \tSubst{\_}{\delta}). ~ \tEq{\sigma_f}{\sigma_g \cdot \sigma} \times \interpr{\subst{\sigma_g}{cs_2}} &&
\end{flalign*}

\paragraph{Resolution Progress}

To keep us from returning the original constraints as output we postulate that every constraint we return is either unsatisfiable or does not have a most general unifier.
Given $\func{solve}~cs_1 \equiv (\sigma, cs_2)$ we have that:
\begin{flalign*}
&\forall c \to c \in cs_2 \to \type{NotMostGeneral}~c ~ \type{\uplus} ~ \type{IsUnsat}~c &&
\end{flalign*}
where
\begin{flalign*}
& \type{NotMostGeneral}~c && \triangleq \exists \sigma_1. \interpr{\subst{\sigma_1}{c}} \times \exists \sigma_2. ~ \interpr{\subst{\sigma_2}{c}} \times \sigma_1 \not\doteq \sigma_2 && \\
& \type{IsUnsat}~c && \triangleq \neg \exists \sigma. ~ \interpr{\subst{\sigma}{c}} &&
\end{flalign*}

\bibliographystyle{abbrvnat}
\bibliography{paper}
\end{document}