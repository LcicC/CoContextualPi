\documentclass[sigplan,screen,review]{acmart}

\usepackage{todonotes}

\renewcommand*{\sectionautorefname}{\S\!\!\,}
\renewcommand*{\subsectionautorefname}{\S\!\!\,}

% Typing rules
\usepackage{mathpartir}
\mprset {sep=0.5em} % Horizontal space between premises

\newcommand{\picalc}{$\pi$-calculus}
\newcommand{\Picalc}{$\pi$-Calculus}
\newcommand{\rulename}[1]{{\tiny \textsc{(#1)}}}
\newcommand{\constr}[1]{\textcolor{olive}{\mathtt{#1}}}
\newcommand{\func}[1]{\textcolor{gray}{\mathtt{#1}}}
\newcommand{\type}[1]{\textcolor{blue}{\mathtt{#1}}}

% Syntax types
\newcommand{\Fin}[1]{\type{Fin}~#1}
\newcommand{\fzero}{\constr{zero}}
\newcommand{\fsuc}{\constr{suc}}
\newcommand{\sExpr}[1]{\type{Expr}~#1}
\newcommand{\sProc}[1]{\type{Proc}~#1}
\newcommand{\tvar}[2]{#1 ~\type{\ni_t}~ #2}
\newcommand{\tkind}[2]{#1 ~\type{\vdash_t}~ #2}
\newcommand{\ttype}[1]{\type{Type}~#1}
\newcommand{\tusage}[1]{\type{Usage}~#1}
\newcommand{\tCtx}[2]{\type{Ctx}_{#1}~#2}
\newcommand{\tSplit}[3]{#1~\type{=}~#2~\type{\uplus}~#3}
\newcommand{\tEq}[2]{#1~\type{\equiv}~#2}
\newcommand{\tun}[1]{\type{un}~#1}
\newcommand{\tVar}[3]{#1 ~ \type{\ni} ~ #2 ~ \type{:} ~ #3}
\newcommand{\tExpr}[3]{#1 ~ \type{\vdash} ~ #2 ~ \type{:} ~ #3}
\newcommand{\tProc}[2]{#1 ~ \type{\vdash} ~ #2}
\newcommand{\tConstr}[1]{\type{Constr} ~ #1}
\newcommand{\tConstrs}[1]{\type{[Constr} ~ #1 ~ \type{]}}

% Syntax constructors
\newcommand{\sunit}{\constr{unit}}
\newcommand{\svar}{\constr{var}}
\newcommand{\sfst}{\constr{fst}}
\newcommand{\ssnd}{\constr{snd}}
\newcommand{\sinl}{\constr{inl}}
\newcommand{\sinr}{\constr{inr}}
\newcommand{\spair}{\constr{pair}}
\newcommand{\send}{\constr{end}}
\newcommand{\snew}{\constr{new}}
\newcommand{\scomp}{\constr{comp}}
\newcommand{\srecv}{\constr{recv}}
\newcommand{\ssend}{\constr{send}}
\newcommand{\scase}{\constr{case}}
\newcommand{\srec}{\constr{rec}}

% Kind constructors
\newcommand{\ktype}{\constr{ty}}
\newcommand{\kusage}{\constr{us}}

% Typing judgment constructors
\newcommand{\tmvar}{\constr{mvar}}
\newcommand{\tchan}{\constr{chan}}
\newcommand{\tunit}{\constr{unit}}
\newcommand{\tsum}{\constr{sum}}
\newcommand{\tprod}{\constr{prod}}
\newcommand{\tzero}{\constr{0\cdot}}
\newcommand{\tone}{\constr{1\cdot}}
\newcommand{\tomega}{\constr{\omega\cdot}}

\newcommand{\subst}[2]{#1 ~ \func{\triangleleft} ~ #2}
\newcommand{\tSubst}[2]{\type{Subst}~#1~#2}
\newcommand{\interpr}[1]{\func{[\![} #1 \func{]\!]}}

% Constraint constructors
\newcommand{\eqconstr}[2]{\constr{[} ~ #1 ~ \constr{\stackrel{c}{=}} ~ #2 ~ \constr{]}}
\newcommand{\sumconstr}[3]{\constr{[} ~ #1 ~ \constr{\stackrel{c}{=}} ~ #2 ~ \constr{+} ~ #3 ~ \constr{]}}

\title
[Co-Contextual Type Inference for the Linear \Picalc{} in Agda]
{Co-Contextual Type Inference \\ for the Linear \Picalc{} in Agda}
\subtitle{(Extended Abstract)}

\author{Uma Zalakain}
\affiliation{University of Glasgow}
\email{u.zalakain.1@research.gla.ac.uk}

\author{Ornela Dardha}
\affiliation{University of Glasgow}
\email{ornela.dardha@glasgow.ac.uk}

\begin{document}

\begin{abstract}
  The linear \picalc{} is a well-known substructural type system for the \picalc{} and a common target for the encoding of session-typed languages \cite{DardhaGS17}.

  To make the type checking of the linear \picalc{} decidable newly created channels must have their types synthesized.
  Inferring these types can prove challenging: not all their typing constraints are local and some cannot be eagerly solved and need to be deferred.

  Following \cite{Padovani15}, we first provide a \emph{co-contextual type inference} \cite{ErdwegBKKM15} algorithm that traverses processes bottom-up collecting constraints; then we solve some of these constraints using well-known unification algorithms \cite{McBride03}, and defer the ones that are unsatisfiable or not uniquely determined.
  We propose clear soundness and completeness theorems for both these stages and a progress theorem that ensures that only unsatisfiable and non-uniquely determined constraints are deferred.
  The totality of this work is being mechanised in Agda.
\end{abstract}


\maketitle

\section{Introduction}\label{introduction}

Consider a linear \picalc{} process with a free channel variable $x$ and wherein we create a new channel $y$, use $y$ to transmit, then send $y$ away over $x$ and terminate.
Unless the payload type of $x$ is determined elsewhere, the usage annotations for the channel $y$ are polymorphic, and the output capability on $y$ requires a lower bound of multiplicity $\tone$ (since the process uses it to transmit).
This lower bound is a constraint that cannot be solved locally: it needs to be deferred until it is further constrained elsewhere.

We use co-contextual type inference \cite{ErdwegBKKM15} to traverse processes bottom-up and infer a context of \emph{requirements} for any given process.
Collecting constraints bottom-up makes type-inference easily parallelisable.
This process is broken down into the collection of constraints (\autoref{constraint-collection}) and their (partial) resolution (\autoref{constraint-resolution}).
We start defining an untyped but well scoped \picalc{} using type-level de Bruijn \cite{deBruijn72} indices --- the syntax for processes contains a small expression language that handles composite sum and product types.
We define a standard linear type system on top of the syntax using context-splits.

Both types and usage annotations contain metavariables (holes).
We keep a common context of metavariables for both types and usage annotations and use kinds to distinguish them.
Substitution respects kindedness, and constraints are uniformly defined over both types and usage annotations.
Context splits are solved by creating an extra fresh context together with constraints that bind the three.
\textbf{We prove that the collection of constraints is sound and postulate a completeness theorem} (\autoref{constraint-collection}).

Constraints of the form $\eqconstr{x}{y}$ are solved by unification using a kinded version of McBride's unification by structural recursion \cite{McBride03}.
Constraints of the form $\sumconstr{x}{y}{z}$ are solved recursively until a base case is reached, at which point they are either admitted as valid (and result in a substitution), not uniquely determined, or unsatisfiable.
\textbf{We postulate soundness and completeness theorems for constraint solving and show that only those constraints without a unique solution are deferred} (\autoref{constraint-resolution}).

\textbf{The totality of this work is being mechanised in Agda.}
We have shown the soundness of constraint collection and the soundness of equality constraint resolution (adapting McBride's work \cite{McBride03} to deal with intrinsically kinded terms).
The remainder proofs are still in progress. 

(Variables are black, \textcolor{blue}{types are blue}, \textcolor{olive}{constructors are green}, \textcolor{gray}{functions are gray}, and we are sorry this is not a poem.)


\section{Type System}

We define a standard syntax and type system for the linear \picalc{}.
The only non-standard feature is that types allow for metavariables (holes) within them.

\paragraph{Syntax}
\label{syntax}

We define a standard syntax for the \picalc{} using type-level de Bruijn indices.
Variable references $i_n$ are of type $\Fin{n}$, expressions $e_n$ and $f_n$ are of type $\sExpr{n}$, processes $p_n$ and $q_n$ are of type $\sProc{n}$.
\todo{add type assertions}
\[
\begin{aligned}[c]
  e_n ~ f_n  :=
  &~ \sunit \\
  |&~ \svar~i_n \\
  |&~ \spair~e_n~f_n \\
  |&~ \sfst~e_n ~|~  \ssnd~e_n \\
  |&~ \sinl~e_n ~|~  \sinr~e_n
\end{aligned}
\begin{aligned}[c]
  p_n ~ q_n  :=
  &~ \send ~|~  \srec~p_n ~|~ \snew~p_{1+n} \\
  |&~ \srecv~e_n~p_{1+n} \\
  |&~ \ssend~e_n~f_n~p_n \\
  |&~ \scomp~p_n~q_n \\
  |&~ \scase~e_n~p_{1+n}~q_{1+n} \\
\end{aligned}
\]

\paragraph{Types}
\label{types}

Both types and usage annotations allow for \emph{holes} or \emph{metavariables}.
We use a common set of metavariables for both types and usage annotations -- this makes their handling uniform.
A context of kinds \(\gamma\) keeps track of whether a metavariable is of type kind $\ktype$ or usage annotation kind $\kusage$.
We refer to a metavariable of kind \(k\) in a kinding context \(\gamma\) as $\tvar{\gamma}{k}$.
We can now define usage annotations and types in one go (note that we define $\tsum$ and $\tprod$ together for brevity):
\begin{mathpar}
  \inferrule {m : \tvar{\gamma}{k}} {\tmvar~m : \tkind{\gamma}{k}}

  \inferrule {
    i : \tkind{\gamma}{\kusage} \\
    o : \tkind{\gamma}{\kusage} \\
    t : \tkind{\gamma}{\ktype}}
  {\tchan~i~o~t : \tkind{\gamma}{\ktype}}

  \inferrule { }
  {\tunit : \tkind{\gamma}{\ktype}}

  \inferrule {s : \tkind{\gamma}{\ktype} \\ t : \tkind{\gamma}{\ktype} }
  {\tsum~s~t ~|~ \tprod~s~t : \tkind{\gamma}{\ktype}}

  \inferrule { } {\tzero : \tkind{\gamma}{\kusage}}

  \inferrule { } {\tone : \tkind{\gamma}{\kusage}}

  \inferrule { } {\tomega : \tkind{\gamma}{\kusage}}
\end{mathpar}
For convenience we henceforth use $\ttype{\gamma}$ to stand for $\tkind{\gamma}{\ktype}$ and $\tusage{\gamma}$ to stand for $\tkind{\gamma}{\kusage}$.

\paragraph{Context Splits}
\label{types}
A context $\Gamma$ of type $\tCtx{n}{\gamma}$ is a list of $\ttype{\gamma}$ of size $n$.
We define context splits $\tSplit{\Gamma}{\Delta}{\Theta}$ pointwise on types.
Splits on types are defined recursively pointwise on usage annotations -- note however that only the usage annotations on the top level of a channel (that is, not within its payload) are split.
Splits on usage annotations are defined as follows -- note that they are not necessarily unique:
\begin{mathpar}
  \inferrule { } {\tSplit{x}{x}{\tzero}}

  \inferrule { } {\tSplit{x}{\tzero}{x}}

  \inferrule { } {\tSplit{\tomega}{x}{y}}
\end{mathpar}
Following \cite{Padovani15}, we say a context $\Gamma$ is unrestricted (shared, non-linear) $\tun{\Gamma}$ if it can be split into itself: $\tSplit{\Gamma}{\Gamma}{\Gamma}$ --- (similarly $\tun{x}$ and $\tun{t}$ for usage annotations $x$ and types $t$, respectively).

\paragraph{Typing Judgments}
\label{typing-judgments}
We can finally define our typing judgment for variables, expressions and processes -- some are omitted for brevity.

\begin{mathpar}
%  \inferrule { \Gamma : \tCtx{n}{\gamma} \\ i : \Fin{n} \\ t : \ttype{\gamma} }
%             { \tVar{\Gamma}{i}{t} }

  \inferrule { \Gamma : \tCtx{n}{\gamma} \\ \tun{\Gamma} \\ t : \ttype{\gamma} }
             { \tVar{\Gamma,t}{\fzero}{t} }
             % \rulename{zero}

  \inferrule { \tVar{\Gamma}{i}{t} \\ s : \ttype{\gamma} \\ \tun{s} }
             { \tVar{\Gamma,s}{\fsuc~i}{t} }
             % \rulename{suc}

%  \inferrule { \Gamma : \tCtx{n}{\gamma} \\ e : \sExpr{n} \\ t : \ttype{\gamma}}
%             { \tExpr{\Gamma}{e}{t} }

  \inferrule { \tVar{\Gamma}{i}{t} } { \tExpr{\Gamma}{\svar~i}{t} }
             % \rulename{var}

  \inferrule { \tun{\Gamma} } { \tExpr{\Gamma}{\sunit}{\tunit} }
             % \rulename{unit}

  \inferrule { \tExpr{\Gamma}{e}{\tprod~t~s} \\ \tun{s}} {\tExpr{\Gamma}{\sfst~e}{t}}
             % \rulename{fst}

  \inferrule { \tExpr{\Gamma}{e}{t} } { \tExpr{\Gamma}{\sinl~e}{\tsum~t~s}}
             % \rulename{inl}

  \inferrule { \tSplit{\Gamma}{\Delta}{\Theta} \\ \tExpr{\Delta}{e}{s} \\ \tExpr{\Theta}{f}{t} }
             { \tExpr{\Gamma}{\spair~e~f}{\tprod~s~t}}
             %\rulename{pair}

%  \inferrule { \Gamma : \tCtx{n}{\gamma} \\ p : \sProc{n}}
%             { \tProc{\Gamma}{p} }

  \inferrule { \tun{\Gamma} } { \tProc{\Gamma}{\send} }
             %\rulename{end}

  \inferrule { \tProc{\Gamma}{p} \\ \tun{\Gamma} }
             { \tProc{\Gamma}{\srec~p} }
             %\rulename{rec}

  \inferrule { t : \ttype{\gamma} \\ \tProc{\Gamma , t}{p} } { \tProc{\Gamma}{\snew~p} }
             %\rulename{new}

  \inferrule { \tSplit{\Gamma}{\Delta}{\Theta} \\ \tExpr{\Delta}{e}{\tchan~\tone~\tzero~t} \\ \tProc{\Theta,t}{p} }
             { \tProc{\Gamma}{\srecv~e~p} }
             %\rulename{recv}

  \inferrule { \tSplit{\Gamma}{\Delta}{\Theta} \\ \tExpr{\Delta}{e}{\tsum~s~t} \\ \tProc{\Theta,s}{p} \\ \tProc{\Theta,t}{q} }
             { \tProc{\Gamma}{\scase~e~p~q} }
             %\rulename{case}
\end{mathpar}

     
\section{Inference}\label{inference}

Co-contextual type inference traverses processes bottom-up collecting constraints.
This has the advantage of making inference subproblems independent and thus easily parallelisable.
For the shared \picalc{}, inference constraints amount to unification problems that can always be eagerly solved.
The linear \picalc{} however requires that some constraints are deferred to a later stage, when more information becomes available elsewhere.

Consider the open process $\ssend~a~\sunit~(\ssend~x~a~\send)$ where $x$ and $a$ are free: we send the unit over $a$, then send $a$ over $x$ and terminate.
By the time we reach $\send$ both $x$ and $a$ must be unrestricted, and thus channel $x$ must be of some type $\tchan~\tzero~\tone~t$.
Since we send a unit over $a$, $a$ must be of some type $s$ such that $\tSplit{s}{\tchan~\tzero~\tone~\tunit}{t}$.
From this we can infer that both $s$ and $t$ must be a channel type and thus $\tSplit{s_i}{\tzero}{t_i}$ and $\tSplit{s_o}{\tone}{t_o}$ for some $s_i$, $t_i$, $s_o$ and $t_o$.
We cannot however infer these usage annotations: all we can deduce is their lower bounds $\tzero$ and $\tone$.
The resolution of these constraints must be deferred until more information becomes available in the context of this open process.

In \autoref{constraint-collection} we introduce typing constraints, define substitution and constraint satisfaction, and provide a typing inference algorithm.
We show that satisfying the constraints generated by typing inference is enough to make a process typable (soundness), and postulate that for any typable process typing inference will find the most general set of constraints that makes the process typable (completeness).

In \autoref{constraint-resolution} we solve equality constraints by unification and context split constraints by decomposition.
Constraints have either no solution, a unique solution, or multiple possible solutions.
(Committing to a non-unique solution can prove to be the wrong choice in an open process, and thus we avoid doing so.
Closed processes can have non-unique solutions safely instantiated.)
Solving a set of constraints results in a set of substitutions and a set of simplified constraints where those substitutions have already been performed.
We postulate that satisfying the simplified constraints amounts to satisfying the original constraints after substitution (soundness), and that for every substitution that solves the original constraints we can find a most general substitution that will solve the simplified constraints (completeness).
Additionally, we postulate that the simplified set of constraints only contains unsatisfiable or non-uniquely satisfiable constraints (progress).

\subsection{Constraint Collection}
\label{constraint-collection}

\paragraph{Constraints}

Constraints of type $\tConstr{\gamma}$ are defined on arguments of type $\tkind{\gamma}{k}$ for some $k$ --- that is, both usage annotations and types.
They take two forms: the binary $\eqconstr{S}{T}$, where $S$ and $T$ are meant to be unified, and the ternary $\sumconstr{S}{T}{R}$, where $T$ and $R$ are meant to be added up to $S$.
Constraints of the former form can \emph{always} be eagerly solved, while constraints of the latter can \emph{sometimes} not, and must be deferred.
We use $\tConstrs{\gamma}$ to refer to lists of constraints of type $\tConstr{\gamma}$.

\paragraph{Substitution}

A substitution $\tSubst{\gamma}{\delta}$ maps usage annotation and type metavariables in $\gamma$ to usage annotations and types in $\delta$, that is, $\forall k \to \tvar{\gamma}{k} \to \tkind{\delta}{k}$.
The function $\subst{\sigma}{t}$ of type $\tSubst{\gamma}{\delta} \to (\forall k \to \tkind{\gamma}{k} \to \tkind{\delta}{k})$ performs the substitution by replacing all the metavariables in $t$ with their corresponding terms in $\sigma$.
Substitutions on constraints are defined pointwise on their arguments.

\paragraph{Constraint Satisfaction}

We use a $\interpr{\_}$ function to interpret constraints $\eqconstr{S}{T}$ and $\sumconstr{S}{T}{R}$ into their proof counterparts $\tEq{S}{T}$ and $\tSplit{S}{T}{R}$.

\paragraph{Inference}

We encode type inference as a function that takes processes with $n$ free variables and returns a metavariable context $\gamma$, a typing context with $n$ free variables containing metavariables in $\gamma$, and a list of constraints on those metavariables $\gamma$.
We define a similar function for type inference on expressions, this time also returning a type $\tau$ of type $\ttype{\gamma}$ for the expression:
\begin{flalign*}
& \func{inferProc} : \sProc{n} \to ~ \exists \gamma. ~ \tCtx{n}{\gamma} \times \tConstrs{\gamma} && \\
& \func{inferExpr} : \sExpr{n} \to ~ \exists \gamma. ~ \tCtx{n}{\gamma} \times \tConstrs{\gamma} \times \ttype{\gamma} &&
\end{flalign*}
These functions are total: if processes and expressions are untypable, their constraints will simply be unsolvable.
Let us provide a couple of examples illustrating how this function is defined:

For the expression $\sfst~e$ we first recursively infer $e$: $\func{inferExpr}~e = \gamma,\Gamma,Cs,\tau$.
We then add two fresh metavariables $?t$ and $?s$ of kind $\ktype$ to $\gamma$, add constraints $\eqconstr{\tau}{\tprod~?t~?s}$ and $\sumconstr{?s}{?s}{?s}$ to $cs$, then return $?t$ as the type of $e$.

For the expression $\scase~e~p~q$ we first recursively infer $p$ and $q$ and $e$: $\func{inferProc}~p = \theta_p, (\Theta_p, s) , Cs_p$, $\func{inferProc}~q = \theta_q, (\Theta_q, t) , Cs_q$, and $\func{inferExpr}~e = \delta_e, \Delta_e, Cs_e, \tau$.
We create a new metavariable context $\gamma$ and a new typing context $\Gamma$ where every type is a fresh metavariable in $\gamma$.
We take the union of the metavariables in $\gamma$, $\theta_p$, $\theta_q$ and $\delta_e$
We take the union of the constraints in $Cs_p$, $Cs_q$ and $Cs_e$, and create new constraints $\eqconstr{\Theta_p}{\Theta_q}$, $\sumconstr{\Gamma}{\Delta_e}{\Theta_p}$, and $\eqconstr{\tau}{\tsum~s~t}$ and return $\Gamma$ as the inferred context.

\paragraph{Inference Soundness}

Every substitution \(\sigma\) that makes the constraints hold will make the process typable under the substituted context. Given $\tEq{\func{infer}~p}{\gamma , \Gamma , cs}$ we have that:
\begin{flalign*}
& (\sigma : \tSubst{\gamma}{\delta}) \to \interpr{\subst{\sigma}{cs}} \to \tProc{(\subst{\sigma}{\Gamma})}{p} &&
\end{flalign*}

\paragraph{Inference Completeness}

For every context \(\Delta\) that makes the process typable there exists a most general substitution \(\sigma\) that will solve the constraints and which substitutes in \(\Gamma\) to something more general than \(\Delta\).
We define $\Delta ~ \func{\subseteq} ~ \Gamma$ as $\exists \delta. ~ \exists (\sigma : \tSubst{\_}{\delta}). ~ \tEq{\Delta}{(\subst{\sigma}{\Gamma})}$.
Given $\tEq{\func{infer}~p}{\gamma , \Gamma , cs}$ we have that:
\begin{flalign*}
  &(\Delta : \tCtx{n}{\gamma}) \to \tProc{\Delta}{p} \to && \\
  & \exists \delta. ~ \exists (\sigma : \tSubst{\gamma}{\delta}). ~ \interpr{\subst{\sigma}{cs}} \times \Delta \subseteq (\subst{\sigma}{\Gamma}) &&
\end{flalign*}

\subsection{Constraint Resolution}
\label{constraint-resolution}

Solving a set of constraints results in a set of substitutions and an unsolved set of simplified constraints where those substitutions have already been performed.
Simplified constraints have either no solution, or multiple possible solutions.
Equality constraints are solved by unification following McBride \cite{McBride03}, and are either unsatisfiable or uniquely satisfied --- and thus resulting in a substitution.
Context split constraints are solved recursively until a base case is reached.
$$
\begin{aligned}
\func{solve} &: \tConstrs{\gamma} \to \tSubst{\gamma}{\delta} \times \tConstrs{\delta}
\end{aligned}
$$

\paragraph{Resolution Soundness}

Satisfying the simplified constraints satisfies the original constraints once substitutions are applied: $\tEq{\func{solve}~cs_1}{(\sigma, cs_2)}$ we have that:
\[
\begin{aligned}
& (\sigma_f : \tSubst{\gamma}{\delta}) \to \interpr{\subst{\sigma_f}{cs_2}} \to \interpr{\subst{\sigma_f \cdot \sigma}{cs_1}}
\end{aligned}
\]

\paragraph{Resolution Completeness}

Any substitution \(\sigma_f\) that makes the original constraints \(cs_1\) hold will be a specialisation \(\sigma_g\) of the returned substitution \(\sigma\).
The specialisation \(\sigma_g\) makes the returned constraints \(cs_2\) hold.
Given $\tEq{\func{solve}~cs_1}{(\sigma, cs_2)}$ we have that:
\begin{flalign*}
&(\sigma_f : \tSubst{\gamma}{\delta}) \to \interpr{\subst{\sigma_f}{cs_1}} \to && \\
&\exists (\sigma_g : \tSubst{\_}{\delta}). ~ \tEq{\sigma_f}{\sigma_g \cdot \sigma} \times \interpr{\subst{\sigma_g}{cs_2}} &&
\end{flalign*}

\paragraph{Resolution Progress}

To keep us from returning the original constraints as output we postulate that every constraint we return is either unsatisfiable or not uniquely satisfied.
Given $\func{solve}~cs_1 \equiv (\sigma, cs_2)$ we have that:
\begin{flalign*}
&\forall c \to c \in cs_2 \to \type{IsNotUnique}~c ~ \type{\uplus} ~ \type{IsUnsat}~c &&
\end{flalign*}
where
\begin{flalign*}
& \type{IsNotUnique}~c && \triangleq \exists \sigma_1. \interpr{\subst{\sigma_1}{c}} \times \exists \sigma_2. ~ \interpr{\subst{\sigma_2}{c}} \times \sigma_1 \not\doteq \sigma_2 && \\
& \type{IsUnsat}~c && \triangleq \neg \exists \sigma. ~ \interpr{\subst{\sigma}{c}} &&
\end{flalign*}

\bibliographystyle{abbrvnat}
\bibliography{paper}
\end{document}